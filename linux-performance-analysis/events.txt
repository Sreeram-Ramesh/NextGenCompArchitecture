
tool:
  duration_time
  user_time
  system_time
  branch-instructions OR cpu_atom/branch-instructions/[Kernel PMU event]
  branch-misses OR cpu_atom/branch-misses/           [Kernel PMU event]
  bus-cycles OR cpu_atom/bus-cycles/                 [Kernel PMU event]
  cache-misses OR cpu_atom/cache-misses/             [Kernel PMU event]
  cache-references OR cpu_atom/cache-references/     [Kernel PMU event]
  cpu-cycles OR cpu_atom/cpu-cycles/                 [Kernel PMU event]
  instructions OR cpu_atom/instructions/             [Kernel PMU event]
  mem-loads OR cpu_atom/mem-loads/                   [Kernel PMU event]
  mem-stores OR cpu_atom/mem-stores/                 [Kernel PMU event]
  ref-cycles OR cpu_atom/ref-cycles/                 [Kernel PMU event]
  topdown-bad-spec OR cpu_atom/topdown-bad-spec/     [Kernel PMU event]
  topdown-be-bound OR cpu_atom/topdown-be-bound/     [Kernel PMU event]
  topdown-fe-bound OR cpu_atom/topdown-fe-bound/     [Kernel PMU event]
  topdown-retiring OR cpu_atom/topdown-retiring/     [Kernel PMU event]
  branch-instructions OR cpu_core/branch-instructions/[Kernel PMU event]
  branch-misses OR cpu_core/branch-misses/           [Kernel PMU event]
  bus-cycles OR cpu_core/bus-cycles/                 [Kernel PMU event]
  cache-misses OR cpu_core/cache-misses/             [Kernel PMU event]
  cache-references OR cpu_core/cache-references/     [Kernel PMU event]
  cpu-cycles OR cpu_core/cpu-cycles/                 [Kernel PMU event]
  instructions OR cpu_core/instructions/             [Kernel PMU event]
  mem-loads OR cpu_core/mem-loads/                   [Kernel PMU event]
  mem-loads-aux OR cpu_core/mem-loads-aux/           [Kernel PMU event]
  mem-stores OR cpu_core/mem-stores/                 [Kernel PMU event]
  ref-cycles OR cpu_core/ref-cycles/                 [Kernel PMU event]
  slots OR cpu_core/slots/                           [Kernel PMU event]
  topdown-bad-spec OR cpu_core/topdown-bad-spec/     [Kernel PMU event]
  topdown-be-bound OR cpu_core/topdown-be-bound/     [Kernel PMU event]
  topdown-br-mispredict OR cpu_core/topdown-br-mispredict/[Kernel PMU event]
  topdown-fe-bound OR cpu_core/topdown-fe-bound/     [Kernel PMU event]
  topdown-fetch-lat OR cpu_core/topdown-fetch-lat/   [Kernel PMU event]
  topdown-heavy-ops OR cpu_core/topdown-heavy-ops/   [Kernel PMU event]
  topdown-mem-bound OR cpu_core/topdown-mem-bound/   [Kernel PMU event]
  topdown-retiring OR cpu_core/topdown-retiring/     [Kernel PMU event]
  cstate_core/c1-residency/                          [Kernel PMU event]
  cstate_core/c6-residency/                          [Kernel PMU event]
  cstate_core/c7-residency/                          [Kernel PMU event]
  cstate_pkg/c10-residency/                          [Kernel PMU event]
  cstate_pkg/c2-residency/                           [Kernel PMU event]
  cstate_pkg/c3-residency/                           [Kernel PMU event]
  cstate_pkg/c6-residency/                           [Kernel PMU event]
  cstate_pkg/c7-residency/                           [Kernel PMU event]
  cstate_pkg/c8-residency/                           [Kernel PMU event]
  cstate_pkg/c9-residency/                           [Kernel PMU event]
  i915/actual-frequency/                             [Kernel PMU event]
  i915/bcs0-busy/                                    [Kernel PMU event]
  i915/bcs0-sema/                                    [Kernel PMU event]
  i915/bcs0-wait/                                    [Kernel PMU event]
  i915/interrupts/                                   [Kernel PMU event]
  i915/rc6-residency/                                [Kernel PMU event]
  i915/rcs0-busy/                                    [Kernel PMU event]
  i915/rcs0-sema/                                    [Kernel PMU event]
  i915/rcs0-wait/                                    [Kernel PMU event]
  i915/requested-frequency/                          [Kernel PMU event]
  i915/software-gt-awake-time/                       [Kernel PMU event]
  i915/vcs0-busy/                                    [Kernel PMU event]
  i915/vcs0-sema/                                    [Kernel PMU event]
  i915/vcs0-wait/                                    [Kernel PMU event]
  i915/vcs1-busy/                                    [Kernel PMU event]
  i915/vcs1-sema/                                    [Kernel PMU event]
  i915/vcs1-wait/                                    [Kernel PMU event]
  i915/vecs0-busy/                                   [Kernel PMU event]
  i915/vecs0-sema/                                   [Kernel PMU event]
  i915/vecs0-wait/                                   [Kernel PMU event]
  intel_bts//                                        [Kernel PMU event]
  intel_pt//                                         [Kernel PMU event]
  msr/aperf/                                         [Kernel PMU event]
  msr/cpu_thermal_margin/                            [Kernel PMU event]
  msr/mperf/                                         [Kernel PMU event]
  msr/pperf/                                         [Kernel PMU event]
  msr/smi/                                           [Kernel PMU event]
  msr/tsc/                                           [Kernel PMU event]
  power/energy-cores/                                [Kernel PMU event]
  power/energy-gpu/                                  [Kernel PMU event]
  power/energy-pkg/                                  [Kernel PMU event]
  power/energy-psys/                                 [Kernel PMU event]
  uncore_clock/clockticks/                           [Kernel PMU event]
  uncore_imc_free_running/data_read/                 [Kernel PMU event]
  uncore_imc_free_running/data_total/                [Kernel PMU event]
  uncore_imc_free_running/data_write/                [Kernel PMU event]

cache:
  longest_lat_cache.miss
       [Counts the number of cacheable memory requests that miss in the LLC.
        Counts on a per core basis. Unit: cpu_atom]
  longest_lat_cache.reference
       [Counts the number of cacheable memory requests that access the LLC.
        Counts on a per core basis. Unit: cpu_atom]
  mem_bound_stalls.ifetch
       [Counts the number of cycles the core is stalled due to an instruction
        cache or TLB miss which hit in the L2, LLC, DRAM or MMIO (Non-DRAM).
        Unit: cpu_atom]
  mem_bound_stalls.ifetch_dram_hit
       [Counts the number of cycles the core is stalled due to an instruction
        cache or TLB miss which hit in DRAM or MMIO (Non-DRAM). Unit: cpu_atom]
  mem_bound_stalls.ifetch_l2_hit
       [Counts the number of cycles the core is stalled due to an instruction
        cache or TLB miss which hit in the L2 cache. Unit: cpu_atom]
  mem_bound_stalls.ifetch_llc_hit
       [Counts the number of cycles the core is stalled due to an instruction
        cache or TLB miss which hit in the LLC or other core with HITE/F/M.
        Unit: cpu_atom]
  mem_bound_stalls.load
       [Counts the number of cycles the core is stalled due to a demand load
        miss which hit in the L2, LLC, DRAM or MMIO (Non-DRAM). Unit: cpu_atom]
  mem_bound_stalls.load_dram_hit
       [Counts the number of cycles the core is stalled due to a demand load
        miss which hit in DRAM or MMIO (Non-DRAM). Unit: cpu_atom]
  mem_bound_stalls.load_l2_hit
       [Counts the number of cycles the core is stalled due to a demand load
        which hit in the L2 cache. Unit: cpu_atom]
  mem_bound_stalls.load_llc_hit
       [Counts the number of cycles the core is stalled due to a demand load
        which hit in the LLC or other core with HITE/F/M. Unit: cpu_atom]
  mem_load_uops_retired.dram_hit
       [Counts the number of load uops retired that hit in DRAM Supports
        address when precise (Precise event). Unit: cpu_atom]
  mem_load_uops_retired.l2_hit
       [Counts the number of load uops retired that hit in the L2 cache
        Supports address when precise (Precise event). Unit: cpu_atom]
  mem_load_uops_retired.l3_hit
       [Counts the number of load uops retired that hit in the L3 cache
        Supports address when precise (Precise event). Unit: cpu_atom]
  mem_scheduler_block.all
       [Counts the number of cycles that uops are blocked for any of the
        following reasons: load buffer, store buffer or RSV full. Unit:
        cpu_atom]
  mem_scheduler_block.ld_buf
       [Counts the number of cycles that uops are blocked due to a load buffer
        full condition. Unit: cpu_atom]
  mem_scheduler_block.rsv
       [Counts the number of cycles that uops are blocked due to an RSV full
        condition. Unit: cpu_atom]
  mem_scheduler_block.st_buf
       [Counts the number of cycles that uops are blocked due to a store
        buffer full condition. Unit: cpu_atom]
  mem_uops_retired.all_loads
       [Counts the number of load uops retired Supports address when precise
        (Precise event). Unit: cpu_atom]
  mem_uops_retired.all_stores
       [Counts the number of store uops retired Supports address when precise
        (Precise event). Unit: cpu_atom]
  mem_uops_retired.load_latency_gt_128
       [Counts the number of tagged loads with an instruction latency that
        exceeds or equals the threshold of 128 cycles as defined in
        MEC_CR_PEBS_LD_LAT_THRESHOLD (3F6H). Only counts with PEBS enabled
        Supports address when precise (Must be precise). Unit: cpu_atom]
  mem_uops_retired.load_latency_gt_16
       [Counts the number of tagged loads with an instruction latency that
        exceeds or equals the threshold of 16 cycles as defined in
        MEC_CR_PEBS_LD_LAT_THRESHOLD (3F6H). Only counts with PEBS enabled
        Supports address when precise (Must be precise). Unit: cpu_atom]
  mem_uops_retired.load_latency_gt_256
       [Counts the number of tagged loads with an instruction latency that
        exceeds or equals the threshold of 256 cycles as defined in
        MEC_CR_PEBS_LD_LAT_THRESHOLD (3F6H). Only counts with PEBS enabled
        Supports address when precise (Must be precise). Unit: cpu_atom]
  mem_uops_retired.load_latency_gt_32
       [Counts the number of tagged loads with an instruction latency that
        exceeds or equals the threshold of 32 cycles as defined in
        MEC_CR_PEBS_LD_LAT_THRESHOLD (3F6H). Only counts with PEBS enabled
        Supports address when precise (Must be precise). Unit: cpu_atom]
  mem_uops_retired.load_latency_gt_4
       [Counts the number of tagged loads with an instruction latency that
        exceeds or equals the threshold of 4 cycles as defined in
        MEC_CR_PEBS_LD_LAT_THRESHOLD (3F6H). Only counts with PEBS enabled
        Supports address when precise (Must be precise). Unit: cpu_atom]
  mem_uops_retired.load_latency_gt_512
       [Counts the number of tagged loads with an instruction latency that
        exceeds or equals the threshold of 512 cycles as defined in
        MEC_CR_PEBS_LD_LAT_THRESHOLD (3F6H). Only counts with PEBS enabled
        Supports address when precise (Must be precise). Unit: cpu_atom]
  mem_uops_retired.load_latency_gt_64
       [Counts the number of tagged loads with an instruction latency that
        exceeds or equals the threshold of 64 cycles as defined in
        MEC_CR_PEBS_LD_LAT_THRESHOLD (3F6H). Only counts with PEBS enabled
        Supports address when precise (Must be precise). Unit: cpu_atom]
  mem_uops_retired.load_latency_gt_8
       [Counts the number of tagged loads with an instruction latency that
        exceeds or equals the threshold of 8 cycles as defined in
        MEC_CR_PEBS_LD_LAT_THRESHOLD (3F6H). Only counts with PEBS enabled
        Supports address when precise (Must be precise). Unit: cpu_atom]
  mem_uops_retired.split_loads
       [Counts the number of retired split load uops Supports address when
        precise (Precise event). Unit: cpu_atom]
  mem_uops_retired.store_latency
       [Counts the number of stores uops retired. Counts with or without PEBS
        enabled Supports address when precise (Must be precise). Unit:
        cpu_atom]
  ocr.demand_data_rd.l3_hit
       [Counts demand data reads that were supplied by the L3 cache. Unit:
        cpu_atom]
  ocr.demand_data_rd.l3_hit.snoop_hit_no_fwd
       [Counts demand data reads that were supplied by the L3 cache where a
        snoop was sent, the snoop hit, but no data was forwarded. Unit:
        cpu_atom]
  ocr.demand_data_rd.l3_hit.snoop_hit_with_fwd
       [Counts demand data reads that were supplied by the L3 cache where a
        snoop was sent, the snoop hit, and non-modified data was forwarded.
        Unit: cpu_atom]
  ocr.demand_data_rd.l3_hit.snoop_hitm
       [Counts demand data reads that were supplied by the L3 cache where a
        snoop was sent, the snoop hit, and modified data was forwarded. Unit:
        cpu_atom]
  ocr.demand_rfo.l3_hit
       [Counts demand reads for ownership (RFO) and software prefetches for
        exclusive ownership (PREFETCHW) that were supplied by the L3 cache.
        Unit: cpu_atom]
  ocr.demand_rfo.l3_hit.snoop_hitm
       [Counts demand reads for ownership (RFO) and software prefetches for
        exclusive ownership (PREFETCHW) that were supplied by the L3 cache
        where a snoop was sent, the snoop hit, and modified data was
        forwarded. Unit: cpu_atom]
  topdown_fe_bound.icache
       [Counts the number of issue slots every cycle that were not delivered
        by the frontend due to instruction cache misses. Unit: cpu_atom]
  l1d.hwpf_miss
       [L1D.HWPF_MISS. Unit: cpu_core]
  l1d.replacement
       [Counts the number of cache lines replaced in L1 data cache. Unit:
        cpu_core]
  l1d_pend_miss.fb_full
       [Number of cycles a demand request has waited due to L1D Fill Buffer
        (FB) unavailability. Unit: cpu_core]
  l1d_pend_miss.fb_full_periods
       [Number of phases a demand request has waited due to L1D Fill Buffer
        (FB) unavailability. Unit: cpu_core]
  l1d_pend_miss.l2_stalls
       [Number of cycles a demand request has waited due to L1D due to lack of
        L2 resources. Unit: cpu_core]
  l1d_pend_miss.pending
       [Number of L1D misses that are outstanding. Unit: cpu_core]
  l1d_pend_miss.pending_cycles
       [Cycles with L1D load Misses outstanding. Unit: cpu_core]
  l2_lines_in.all
       [L2 cache lines filling L2. Unit: cpu_core]
  l2_lines_out.useless_hwpf
       [Cache lines that have been L2 hardware prefetched but not used by
        demand accesses. Unit: cpu_core]
  l2_request.all
       [All accesses to L2 cache [This event is alias to L2_RQSTS.REFERENCES].
        Unit: cpu_core]
  l2_request.miss
       [Read requests with true-miss in L2 cache. [This event is alias to
        L2_RQSTS.MISS]. Unit: cpu_core]
  l2_rqsts.all_code_rd
       [L2 code requests. Unit: cpu_core]
  l2_rqsts.all_demand_data_rd
       [Demand Data Read access L2 cache. Unit: cpu_core]
  l2_rqsts.all_demand_miss
       [Demand requests that miss L2 cache. Unit: cpu_core]
  l2_rqsts.all_hwpf
       [L2_RQSTS.ALL_HWPF. Unit: cpu_core]
  l2_rqsts.all_rfo
       [RFO requests to L2 cache. Unit: cpu_core]
  l2_rqsts.code_rd_hit
       [L2 cache hits when fetching instructions, code reads. Unit: cpu_core]
  l2_rqsts.code_rd_miss
       [L2 cache misses when fetching instructions. Unit: cpu_core]
  l2_rqsts.demand_data_rd_hit
       [Demand Data Read requests that hit L2 cache. Unit: cpu_core]
  l2_rqsts.demand_data_rd_miss
       [Demand Data Read miss L2 cache. Unit: cpu_core]
  l2_rqsts.hwpf_miss
       [L2_RQSTS.HWPF_MISS. Unit: cpu_core]
  l2_rqsts.miss
       [Read requests with true-miss in L2 cache. [This event is alias to
        L2_REQUEST.MISS]. Unit: cpu_core]
  l2_rqsts.references
       [All accesses to L2 cache [This event is alias to L2_REQUEST.ALL].
        Unit: cpu_core]
  l2_rqsts.rfo_hit
       [RFO requests that hit L2 cache. Unit: cpu_core]
  l2_rqsts.rfo_miss
       [RFO requests that miss L2 cache. Unit: cpu_core]
  l2_rqsts.swpf_hit
       [SW prefetch requests that hit L2 cache. Unit: cpu_core]
  l2_rqsts.swpf_miss
       [SW prefetch requests that miss L2 cache. Unit: cpu_core]
  longest_lat_cache.miss
       [Core-originated cacheable requests that missed L3 (Except hardware
        prefetches to the L3). Unit: cpu_core]
  longest_lat_cache.reference
       [Core-originated cacheable requests that refer to L3 (Except hardware
        prefetches to the L3). Unit: cpu_core]
  mem_inst_retired.all_loads
       [Retired load instructions Supports address when precise (Precise
        event). Unit: cpu_core]
  mem_inst_retired.all_stores
       [Retired store instructions Supports address when precise (Precise
        event). Unit: cpu_core]
  mem_inst_retired.any
       [All retired memory instructions Supports address when precise (Precise
        event). Unit: cpu_core]
  mem_inst_retired.lock_loads
       [Retired load instructions with locked access Supports address when
        precise (Precise event). Unit: cpu_core]
  mem_inst_retired.split_loads
       [Retired load instructions that split across a cacheline boundary
        Supports address when precise (Precise event). Unit: cpu_core]
  mem_inst_retired.split_stores
       [Retired store instructions that split across a cacheline boundary
        Supports address when precise (Precise event). Unit: cpu_core]
  mem_inst_retired.stlb_miss_loads
       [Retired load instructions that miss the STLB Supports address when
        precise (Precise event). Unit: cpu_core]
  mem_inst_retired.stlb_miss_stores
       [Retired store instructions that miss the STLB Supports address when
        precise (Precise event). Unit: cpu_core]
  mem_load_completed.l1_miss_any
       [Completed demand load uops that miss the L1 d-cache. Unit: cpu_core]
  mem_load_l3_hit_retired.xsnp_fwd
       [Retired load instructions whose data sources were HitM responses from
        shared L3 Supports address when precise (Precise event). Unit:
        cpu_core]
  mem_load_l3_hit_retired.xsnp_hit
       [Retired load instructions whose data sources were L3 and cross-core
        snoop hits in on-pkg core cache Supports address when precise (Precise
        event). Unit: cpu_core]
  mem_load_l3_hit_retired.xsnp_hitm
       [Retired load instructions whose data sources were HitM responses from
        shared L3 Supports address when precise (Precise event). Unit:
        cpu_core]
  mem_load_l3_hit_retired.xsnp_miss
       [Retired load instructions whose data sources were L3 hit and
        cross-core snoop missed in on-pkg core cache Supports address when
        precise (Precise event). Unit: cpu_core]
  mem_load_l3_hit_retired.xsnp_no_fwd
       [Retired load instructions whose data sources were L3 and cross-core
        snoop hits in on-pkg core cache Supports address when precise (Precise
        event). Unit: cpu_core]
  mem_load_l3_hit_retired.xsnp_none
       [Retired load instructions whose data sources were hits in L3 without
        snoops required Supports address when precise (Precise event). Unit:
        cpu_core]
  mem_load_l3_miss_retired.local_dram
       [Retired load instructions which data sources missed L3 but serviced
        from local dram Supports address when precise (Precise event). Unit:
        cpu_core]
  mem_load_misc_retired.uc
       [Retired instructions with at least 1 uncacheable load or lock Supports
        address when precise (Precise event). Unit: cpu_core]
  mem_load_retired.fb_hit
       [Number of completed demand load requests that missed the L1, but hit
        the FB(fill buffer), because a preceding miss to the same cacheline
        initiated the line to be brought into L1, but data is not yet ready in
        L1 Supports address when precise (Precise event). Unit: cpu_core]
  mem_load_retired.l1_hit
       [Retired load instructions with L1 cache hits as data sources Supports
        address when precise (Precise event). Unit: cpu_core]
  mem_load_retired.l1_miss
       [Retired load instructions missed L1 cache as data sources Supports
        address when precise (Precise event). Unit: cpu_core]
  mem_load_retired.l2_hit
       [Retired load instructions with L2 cache hits as data sources Supports
        address when precise (Precise event). Unit: cpu_core]
  mem_load_retired.l2_miss
       [Retired load instructions missed L2 cache as data sources Supports
        address when precise (Precise event). Unit: cpu_core]
  mem_load_retired.l3_hit
       [Retired load instructions with L3 cache hits as data sources Supports
        address when precise (Precise event). Unit: cpu_core]
  mem_load_retired.l3_miss
       [Retired load instructions missed L3 cache as data sources Supports
        address when precise (Precise event). Unit: cpu_core]
  mem_store_retired.l2_hit
       [MEM_STORE_RETIRED.L2_HIT. Unit: cpu_core]
  mem_uop_retired.any
       [Retired memory uops for any access. Unit: cpu_core]
  ocr.demand_data_rd.l3_hit.snoop_hit_with_fwd
       [Counts demand data reads that resulted in a snoop hit in another cores
        caches which forwarded the unmodified data to the requesting core.
        Unit: cpu_core]
  ocr.demand_data_rd.l3_hit.snoop_hitm
       [Counts demand data reads that resulted in a snoop hit in another cores
        caches, data forwarding is required as the data is modified. Unit:
        cpu_core]
  ocr.demand_rfo.l3_hit.snoop_hitm
       [Counts demand read for ownership (RFO) requests and software
        prefetches for exclusive ownership (PREFETCHW) that resulted in a
        snoop hit in another cores caches, data forwarding is required as the
        data is modified. Unit: cpu_core]
  offcore_requests.all_requests
       [OFFCORE_REQUESTS.ALL_REQUESTS. Unit: cpu_core]
  offcore_requests.data_rd
       [Demand and prefetch data reads. Unit: cpu_core]
  offcore_requests.demand_data_rd
       [Demand Data Read requests sent to uncore. Unit: cpu_core]
  offcore_requests_outstanding.cycles_with_data_rd
       [OFFCORE_REQUESTS_OUTSTANDING.CYCLES_WITH_DATA_RD Spec update: ADL038.
        Unit: cpu_core]
  offcore_requests_outstanding.cycles_with_demand_data_rd
       [Cycles where at least 1 outstanding demand data read request is
        pending. Unit: cpu_core]
  offcore_requests_outstanding.cycles_with_demand_rfo
       [For every cycle where the core is waiting on at least 1 outstanding
        Demand RFO request, increments by 1. Unit: cpu_core]
  offcore_requests_outstanding.data_rd
       [OFFCORE_REQUESTS_OUTSTANDING.DATA_RD Spec update: ADL038. Unit:
        cpu_core]
  offcore_requests_outstanding.demand_data_rd
       [For every cycle, increments by the number of outstanding demand data
        read requests pending. Unit: cpu_core]
  sq_misc.bus_lock
       [Counts bus locks, accounts for cache line split locks and UC locks.
        Unit: cpu_core]
  sw_prefetch_access.nta
       [Number of PREFETCHNTA instructions executed. Unit: cpu_core]
  sw_prefetch_access.prefetchw
       [Number of PREFETCHW instructions executed. Unit: cpu_core]
  sw_prefetch_access.t0
       [Number of PREFETCHT0 instructions executed. Unit: cpu_core]
  sw_prefetch_access.t1_t2
       [Number of PREFETCHT1 or PREFETCHT2 instructions executed. Unit:
        cpu_core]

floating point:
  machine_clears.fp_assist
       [Counts the number of floating point operations retired that required
        microcode assist. Unit: cpu_atom]
  uops_retired.fpdiv
       [Counts the number of floating point divide uops retired (x87 and SSE,
        including x87 sqrt) (Precise event). Unit: cpu_atom]
  arith.fpdiv_active
       [ARITH.FPDIV_ACTIVE. Unit: cpu_core]
  assists.fp
       [Counts all microcode FP assists. Unit: cpu_core]
  assists.sse_avx_mix
       [ASSISTS.SSE_AVX_MIX. Unit: cpu_core]
  fp_arith_dispatched.port_0
       [FP_ARITH_DISPATCHED.PORT_0. Unit: cpu_core]
  fp_arith_dispatched.port_1
       [FP_ARITH_DISPATCHED.PORT_1. Unit: cpu_core]
  fp_arith_dispatched.port_5
       [FP_ARITH_DISPATCHED.PORT_5. Unit: cpu_core]
  fp_arith_inst_retired.128b_packed_double
       [Counts number of SSE/AVX computational 128-bit packed double precision
        floating-point instructions retired; some instructions will count
        twice as noted below. Each count represents 2 computation operations,
        one for each element. Applies to SSE* and AVX* packed double precision
        floating-point instructions: ADD SUB HADD HSUB SUBADD MUL DIV MIN MAX
        SQRT DPP FM(N)ADD/SUB. DPP and FM(N)ADD/SUB instructions count twice
        as they perform 2 calculations per element. Unit: cpu_core]
  fp_arith_inst_retired.128b_packed_single
       [Number of SSE/AVX computational 128-bit packed single precision
        floating-point instructions retired; some instructions will count
        twice as noted below. Each count represents 4 computation operations,
        one for each element. Applies to SSE* and AVX* packed single precision
        floating-point instructions: ADD SUB MUL DIV MIN MAX RCP14 RSQRT14
        SQRT DPP FM(N)ADD/SUB. DPP and FM(N)ADD/SUB instructions count twice
        as they perform 2 calculations per element. Unit: cpu_core]
  fp_arith_inst_retired.256b_packed_double
       [Counts number of SSE/AVX computational 256-bit packed double precision
        floating-point instructions retired; some instructions will count
        twice as noted below. Each count represents 4 computation operations,
        one for each element. Applies to SSE* and AVX* packed double precision
        floating-point instructions: ADD SUB HADD HSUB SUBADD MUL DIV MIN MAX
        SQRT FM(N)ADD/SUB. FM(N)ADD/SUB instructions count twice as they
        perform 2 calculations per element. Unit: cpu_core]
  fp_arith_inst_retired.256b_packed_single
       [Counts number of SSE/AVX computational 256-bit packed single precision
        floating-point instructions retired; some instructions will count
        twice as noted below. Each count represents 8 computation operations,
        one for each element. Applies to SSE* and AVX* packed single precision
        floating-point instructions: ADD SUB HADD HSUB SUBADD MUL DIV MIN MAX
        SQRT RSQRT RCP DPP FM(N)ADD/SUB. DPP and FM(N)ADD/SUB instructions
        count twice as they perform 2 calculations per element. Unit: cpu_core]
  fp_arith_inst_retired.4_flops
       [Number of SSE/AVX computational 128-bit packed single and 256-bit
        packed double precision FP instructions retired; some instructions
        will count twice as noted below. Each count represents 2 or/and 4
        computation operations, 1 for each element. Applies to SSE* and AVX*
        packed single precision and packed double precision FP instructions:
        ADD SUB HADD HSUB SUBADD MUL DIV MIN MAX RCP14 RSQRT14 SQRT DPP
        FM(N)ADD/SUB. DPP and FM(N)ADD/SUB count twice as they perform 2
        calculations per element. Unit: cpu_core]
  fp_arith_inst_retired.scalar
       [Number of SSE/AVX computational scalar floating-point instructions
        retired; some instructions will count twice as noted below. Applies to
        SSE* and AVX* scalar, double and single precision floating-point: ADD
        SUB MUL DIV MIN MAX RCP14 RSQRT14 RANGE SQRT DPP FM(N)ADD/SUB. DPP and
        FM(N)ADD/SUB instructions count twice as they perform multiple
        calculations per element. Unit: cpu_core]
  fp_arith_inst_retired.scalar_double
       [Counts number of SSE/AVX computational scalar double precision
        floating-point instructions retired; some instructions will count
        twice as noted below. Each count represents 1 computational operation.
        Applies to SSE* and AVX* scalar double precision floating-point
        instructions: ADD SUB MUL DIV MIN MAX SQRT FM(N)ADD/SUB. FM(N)ADD/SUB
        instructions count twice as they perform 2 calculations per element.
        Unit: cpu_core]
  fp_arith_inst_retired.scalar_single
       [Counts number of SSE/AVX computational scalar single precision
        floating-point instructions retired; some instructions will count
        twice as noted below. Each count represents 1 computational operation.
        Applies to SSE* and AVX* scalar single precision floating-point
        instructions: ADD SUB MUL DIV MIN MAX SQRT RSQRT RCP FM(N)ADD/SUB.
        FM(N)ADD/SUB instructions count twice as they perform 2 calculations
        per element. Unit: cpu_core]
  fp_arith_inst_retired.vector
       [Number of any Vector retired FP arithmetic instructions. Unit:
        cpu_core]

frontend:
  baclears.any
       [Counts the total number of BACLEARS due to all branch types including
        conditional and unconditional jumps, returns, and indirect branches.
        Unit: cpu_atom]
  icache.accesses
       [Counts the number of requests to the instruction cache for one or more
        bytes of a cache line. Unit: cpu_atom]
  icache.misses
       [Counts the number of instruction cache misses. Unit: cpu_atom]
  baclears.any
       [Clears due to Unknown Branches. Unit: cpu_core]
  decode.lcp
       [Stalls caused by changing prefix length of the instruction. Unit:
        cpu_core]
  decode.ms_busy
       [Cycles the Microcode Sequencer is busy. Unit: cpu_core]
  dsb2mite_switches.penalty_cycles
       [DSB-to-MITE switch true penalty cycles. Unit: cpu_core]
  frontend_retired.any_dsb_miss
       [Retired Instructions who experienced DSB miss (Precise event). Unit:
        cpu_core]
  frontend_retired.dsb_miss
       [Retired Instructions who experienced a critical DSB miss (Precise
        event). Unit: cpu_core]
  frontend_retired.itlb_miss
       [Retired Instructions who experienced iTLB true miss (Precise event).
        Unit: cpu_core]
  frontend_retired.l1i_miss
       [Retired Instructions who experienced Instruction L1 Cache true miss
        (Precise event). Unit: cpu_core]
  frontend_retired.l2_miss
       [Retired Instructions who experienced Instruction L2 Cache true miss
        (Precise event). Unit: cpu_core]
  frontend_retired.latency_ge_1
       [Retired instructions after front-end starvation of at least 1 cycle
        (Precise event). Unit: cpu_core]
  frontend_retired.latency_ge_128
       [Retired instructions that are fetched after an interval where the
        front-end delivered no uops for a period of 128 cycles which was not
        interrupted by a back-end stall (Precise event). Unit: cpu_core]
  frontend_retired.latency_ge_16
       [Retired instructions that are fetched after an interval where the
        front-end delivered no uops for a period of 16 cycles which was not
        interrupted by a back-end stall (Precise event). Unit: cpu_core]
  frontend_retired.latency_ge_2
       [Retired instructions after front-end starvation of at least 2 cycles
        (Precise event). Unit: cpu_core]
  frontend_retired.latency_ge_256
       [Retired instructions that are fetched after an interval where the
        front-end delivered no uops for a period of 256 cycles which was not
        interrupted by a back-end stall (Precise event). Unit: cpu_core]
  frontend_retired.latency_ge_2_bubbles_ge_1
       [Retired instructions that are fetched after an interval where the
        front-end had at least 1 bubble-slot for a period of 2 cycles which
        was not interrupted by a back-end stall (Precise event). Unit:
        cpu_core]
  frontend_retired.latency_ge_32
       [Retired instructions that are fetched after an interval where the
        front-end delivered no uops for a period of 32 cycles which was not
        interrupted by a back-end stall (Precise event). Unit: cpu_core]
  frontend_retired.latency_ge_4
       [Retired instructions that are fetched after an interval where the
        front-end delivered no uops for a period of 4 cycles which was not
        interrupted by a back-end stall (Precise event). Unit: cpu_core]
  frontend_retired.latency_ge_512
       [Retired instructions that are fetched after an interval where the
        front-end delivered no uops for a period of 512 cycles which was not
        interrupted by a back-end stall (Precise event). Unit: cpu_core]
  frontend_retired.latency_ge_64
       [Retired instructions that are fetched after an interval where the
        front-end delivered no uops for a period of 64 cycles which was not
        interrupted by a back-end stall (Precise event). Unit: cpu_core]
  frontend_retired.latency_ge_8
       [Retired instructions that are fetched after an interval where the
        front-end delivered no uops for a period of 8 cycles which was not
        interrupted by a back-end stall (Precise event). Unit: cpu_core]
  frontend_retired.ms_flows
       [FRONTEND_RETIRED.MS_FLOWS (Precise event). Unit: cpu_core]
  frontend_retired.stlb_miss
       [Retired Instructions who experienced STLB (2nd level TLB) true miss
        (Precise event). Unit: cpu_core]
  frontend_retired.unknown_branch
       [FRONTEND_RETIRED.UNKNOWN_BRANCH (Precise event). Unit: cpu_core]
  icache_data.stalls
       [Cycles where a code fetch is stalled due to L1 instruction cache miss.
        Unit: cpu_core]
  icache_tag.stalls
       [Cycles where a code fetch is stalled due to L1 instruction cache tag
        miss. Unit: cpu_core]
  idq.dsb_cycles_any
       [Cycles Decode Stream Buffer (DSB) is delivering any Uop. Unit:
        cpu_core]
  idq.dsb_cycles_ok
       [Cycles DSB is delivering optimal number of Uops. Unit: cpu_core]
  idq.dsb_uops
       [Uops delivered to Instruction Decode Queue (IDQ) from the Decode
        Stream Buffer (DSB) path. Unit: cpu_core]
  idq.mite_cycles_any
       [Cycles MITE is delivering any Uop. Unit: cpu_core]
  idq.mite_cycles_ok
       [Cycles MITE is delivering optimal number of Uops. Unit: cpu_core]
  idq.mite_uops
       [Uops delivered to Instruction Decode Queue (IDQ) from MITE path. Unit:
        cpu_core]
  idq.ms_cycles_any
       [Cycles when uops are being delivered to IDQ while MS is busy. Unit:
        cpu_core]
  idq.ms_switches
       [Number of switches from DSB or MITE to the MS. Unit: cpu_core]
  idq.ms_uops
       [Uops delivered to IDQ while MS is busy. Unit: cpu_core]
  idq_bubbles.core
       [Uops not delivered by IDQ when backend of the machine is not stalled
        [This event is alias to IDQ_UOPS_NOT_DELIVERED.CORE]. Unit: cpu_core]
  idq_bubbles.cycles_0_uops_deliv.core
       [Cycles when no uops are not delivered by the IDQ when backend of the
        machine is not stalled [This event is alias to
        IDQ_UOPS_NOT_DELIVERED.CYCLES_0_UOPS_DELIV.CORE]. Unit: cpu_core]
  idq_bubbles.cycles_fe_was_ok
       [Cycles when optimal number of uops was delivered to the back-end when
        the back-end is not stalled [This event is alias to
        IDQ_UOPS_NOT_DELIVERED.CYCLES_FE_WAS_OK]. Unit: cpu_core]
  idq_uops_not_delivered.core
       [Uops not delivered by IDQ when backend of the machine is not stalled
        [This event is alias to IDQ_BUBBLES.CORE]. Unit: cpu_core]
  idq_uops_not_delivered.cycles_0_uops_deliv.core
       [Cycles when no uops are not delivered by the IDQ when backend of the
        machine is not stalled [This event is alias to
        IDQ_BUBBLES.CYCLES_0_UOPS_DELIV.CORE]. Unit: cpu_core]
  idq_uops_not_delivered.cycles_fe_was_ok
       [Cycles when optimal number of uops was delivered to the back-end when
        the back-end is not stalled [This event is alias to
        IDQ_BUBBLES.CYCLES_FE_WAS_OK]. Unit: cpu_core]

memory:
  ld_head.any_at_ret
       [Counts the number of cycles that the head (oldest load) of the load
        buffer is stalled due to any number of reasons, including an L1 miss,
        WCB full, pagewalk, store address block or store data block, on a load
        that retires. Unit: cpu_atom]
  ld_head.l1_bound_at_ret
       [Counts the number of cycles that the head (oldest load) of the load
        buffer is stalled due to a core bound stall including a store address
        match, a DTLB miss or a page walk that detains the load from retiring.
        Unit: cpu_atom]
  ld_head.l1_miss_at_ret
       [Counts the number of cycles that the head (oldest load) of the load
        buffer and retirement are both stalled due to a DL1 miss. Unit:
        cpu_atom]
  ld_head.other_at_ret
       [Counts the number of cycles that the head (oldest load) of the load
        buffer and retirement are both stalled due to other block cases. Unit:
        cpu_atom]
  ld_head.pgwalk_at_ret
       [Counts the number of cycles that the head (oldest load) of the load
        buffer and retirement are both stalled due to a pagewalk. Unit:
        cpu_atom]
  ld_head.st_addr_at_ret
       [Counts the number of cycles that the head (oldest load) of the load
        buffer and retirement are both stalled due to a store address match.
        Unit: cpu_atom]
  machine_clears.memory_ordering
       [Counts the number of machine clears due to memory ordering caused by a
        snoop from an external agent. Does not count internally generated
        machine clears such as those due to memory disambiguation. Unit:
        cpu_atom]
  ocr.demand_data_rd.l3_miss
       [Counts demand data reads that were not supplied by the L3 cache. Unit:
        cpu_atom]
  ocr.demand_data_rd.l3_miss_local
       [Counts demand data reads that were not supplied by the L3 cache.
        [L3_MISS_LOCAL is alias to L3_MISS]. Unit: cpu_atom]
  ocr.demand_rfo.l3_miss
       [Counts demand reads for ownership (RFO) and software prefetches for
        exclusive ownership (PREFETCHW) that were not supplied by the L3
        cache. Unit: cpu_atom]
  ocr.demand_rfo.l3_miss_local
       [Counts demand reads for ownership (RFO) and software prefetches for
        exclusive ownership (PREFETCHW) that were not supplied by the L3
        cache. [L3_MISS_LOCAL is alias to L3_MISS]. Unit: cpu_atom]
  cycle_activity.stalls_l3_miss
       [Execution stalls while L3 cache miss demand load is outstanding. Unit:
        cpu_core]
  machine_clears.memory_ordering
       [Number of machine clears due to memory ordering conflicts. Unit:
        cpu_core]
  mem_trans_retired.load_latency_gt_128
       [Counts randomly selected loads when the latency from first dispatch to
        completion is greater than 128 cycles Supports address when precise
        (Must be precise). Unit: cpu_core]
  mem_trans_retired.load_latency_gt_16
       [Counts randomly selected loads when the latency from first dispatch to
        completion is greater than 16 cycles Supports address when precise
        (Must be precise). Unit: cpu_core]
  mem_trans_retired.load_latency_gt_256
       [Counts randomly selected loads when the latency from first dispatch to
        completion is greater than 256 cycles Supports address when precise
        (Must be precise). Unit: cpu_core]
  mem_trans_retired.load_latency_gt_32
       [Counts randomly selected loads when the latency from first dispatch to
        completion is greater than 32 cycles Supports address when precise
        (Must be precise). Unit: cpu_core]
  mem_trans_retired.load_latency_gt_4
       [Counts randomly selected loads when the latency from first dispatch to
        completion is greater than 4 cycles Supports address when precise
        (Must be precise). Unit: cpu_core]
  mem_trans_retired.load_latency_gt_512
       [Counts randomly selected loads when the latency from first dispatch to
        completion is greater than 512 cycles Supports address when precise
        (Must be precise). Unit: cpu_core]
  mem_trans_retired.load_latency_gt_64
       [Counts randomly selected loads when the latency from first dispatch to
        completion is greater than 64 cycles Supports address when precise
        (Must be precise). Unit: cpu_core]
  mem_trans_retired.load_latency_gt_8
       [Counts randomly selected loads when the latency from first dispatch to
        completion is greater than 8 cycles Supports address when precise
        (Must be precise). Unit: cpu_core]
  mem_trans_retired.store_sample
       [Retired memory store access operations. A PDist event for PEBS Store
        Latency Facility Supports address when precise (Must be precise).
        Unit: cpu_core]
  memory_activity.cycles_l1d_miss
       [Cycles while L1 cache miss demand load is outstanding. Unit: cpu_core]
  memory_activity.stalls_l1d_miss
       [Execution stalls while L1 cache miss demand load is outstanding. Unit:
        cpu_core]
  memory_activity.stalls_l2_miss
       [Execution stalls while L2 cache miss demand cacheable load request is
        outstanding. Unit: cpu_core]
  memory_activity.stalls_l3_miss
       [Execution stalls while L3 cache miss demand cacheable load request is
        outstanding. Unit: cpu_core]
  ocr.demand_data_rd.l3_miss
       [Counts demand data reads that were not supplied by the L3 cache. Unit:
        cpu_core]
  ocr.demand_rfo.l3_miss
       [Counts demand read for ownership (RFO) requests and software
        prefetches for exclusive ownership (PREFETCHW) that were not supplied
        by the L3 cache. Unit: cpu_core]
  offcore_requests.l3_miss_demand_data_rd
       [Counts demand data read requests that miss the L3 cache. Unit:
        cpu_core]
  offcore_requests_outstanding.l3_miss_demand_data_rd
       [For every cycle, increments by the number of demand data read requests
        pending that are known to have missed the L3 cache. Unit: cpu_core]

other:
  ocr.corewb_m.any_response
       [Counts modified writebacks from L1 cache and L2 cache that have any
        type of response. Unit: cpu_atom]
  ocr.demand_data_rd.any_response
       [Counts demand data reads that have any type of response. Unit:
        cpu_atom]
  ocr.demand_rfo.any_response
       [Counts demand reads for ownership (RFO) and software prefetches for
        exclusive ownership (PREFETCHW) that have any type of response. Unit:
        cpu_atom]
  ocr.streaming_wr.any_response
       [Counts streaming stores that have any type of response. Unit: cpu_atom]
  assists.hardware
       [ASSISTS.HARDWARE. Unit: cpu_core]
  assists.page_fault
       [ASSISTS.PAGE_FAULT. Unit: cpu_core]
  core_power.license_1
       [CORE_POWER.LICENSE_1. Unit: cpu_core]
  core_power.license_2
       [CORE_POWER.LICENSE_2. Unit: cpu_core]
  core_power.license_3
       [CORE_POWER.LICENSE_3. Unit: cpu_core]
  ocr.demand_data_rd.any_response
       [Counts demand data reads that have any type of response. Unit:
        cpu_core]
  ocr.demand_data_rd.dram
       [Counts demand data reads that were supplied by DRAM. Unit: cpu_core]
  ocr.demand_rfo.any_response
       [Counts demand read for ownership (RFO) requests and software
        prefetches for exclusive ownership (PREFETCHW) that have any type of
        response. Unit: cpu_core]
  ocr.streaming_wr.any_response
       [Counts streaming stores that have any type of response. Unit: cpu_core]
  rs.empty
       [Cycles when Reservation Station (RS) is empty for the thread. Unit:
        cpu_core]
  rs.empty_count
       [Counts end of periods where the Reservation Station (RS) was empty.
        Unit: cpu_core]
  xq.full_cycles
       [Cycles the uncore cannot take further requests. Unit: cpu_core]

pipeline:
  br_inst_retired.all_branches
       [Counts the total number of branch instructions retired for all branch
        types (Precise event). Unit: cpu_atom]
  br_inst_retired.cond
       [Counts the number of retired JCC (Jump on Conditional Code) branch
        instructions retired, includes both taken and not taken branches
        (Precise event). Unit: cpu_atom]
  br_inst_retired.cond_taken
       [Counts the number of taken JCC (Jump on Conditional Code) branch
        instructions retired (Precise event). Unit: cpu_atom]
  br_inst_retired.far_branch
       [Counts the number of far branch instructions retired, includes far
        jump, far call and return, and interrupt call and return (Precise
        event). Unit: cpu_atom]
  br_inst_retired.indirect
       [Counts the number of near indirect JMP and near indirect CALL branch
        instructions retired (Precise event). Unit: cpu_atom]
  br_inst_retired.indirect_call
       [Counts the number of near indirect CALL branch instructions retired
        (Precise event). Unit: cpu_atom]
  br_inst_retired.near_call
       [Counts the number of near CALL branch instructions retired (Precise
        event). Unit: cpu_atom]
  br_inst_retired.near_return
       [Counts the number of near RET branch instructions retired (Precise
        event). Unit: cpu_atom]
  br_inst_retired.near_taken
       [Counts the number of near taken branch instructions retired (Precise
        event). Unit: cpu_atom]
  br_inst_retired.rel_call
       [Counts the number of near relative CALL branch instructions retired
        (Precise event). Unit: cpu_atom]
  br_misp_retired.all_branches
       [Counts the total number of mispredicted branch instructions retired
        for all branch types (Precise event). Unit: cpu_atom]
  br_misp_retired.cond
       [Counts the number of mispredicted JCC (Jump on Conditional Code)
        branch instructions retired (Precise event). Unit: cpu_atom]
  br_misp_retired.cond_taken
       [Counts the number of mispredicted taken JCC (Jump on Conditional Code)
        branch instructions retired (Precise event). Unit: cpu_atom]
  br_misp_retired.indirect
       [Counts the number of mispredicted near indirect JMP and near indirect
        CALL branch instructions retired (Precise event). Unit: cpu_atom]
  br_misp_retired.indirect_call
       [Counts the number of mispredicted near indirect CALL branch
        instructions retired (Precise event). Unit: cpu_atom]
  br_misp_retired.near_taken
       [Counts the number of mispredicted near taken branch instructions
        retired (Precise event). Unit: cpu_atom]
  br_misp_retired.return
       [Counts the number of mispredicted near RET branch instructions retired
        (Precise event). Unit: cpu_atom]
  cpu_clk_unhalted.core
       [Counts the number of unhalted core clock cycles. (Fixed event). Unit:
        cpu_atom]
  cpu_clk_unhalted.core_p
       [Counts the number of unhalted core clock cycles. Unit: cpu_atom]
  cpu_clk_unhalted.ref_tsc
       [Counts the number of unhalted reference clock cycles at TSC frequency.
        (Fixed event). Unit: cpu_atom]
  cpu_clk_unhalted.ref_tsc_p
       [Counts the number of unhalted reference clock cycles at TSC frequency.
        Unit: cpu_atom]
  cpu_clk_unhalted.thread
       [Counts the number of unhalted core clock cycles. (Fixed event). Unit:
        cpu_atom]
  cpu_clk_unhalted.thread_p
       [Counts the number of unhalted core clock cycles. Unit: cpu_atom]
  inst_retired.any
       [Counts the total number of instructions retired. (Fixed event)
        (Precise event). Unit: cpu_atom]
  inst_retired.any_p
       [Counts the total number of instructions retired (Precise event). Unit:
        cpu_atom]
  ld_blocks.address_alias
       [Counts the number of retired loads that are blocked because it
        initially appears to be store forward blocked, but subsequently is
        shown not to be blocked based on 4K alias check (Precise event). Unit:
        cpu_atom]
  ld_blocks.data_unknown
       [Counts the number of retired loads that are blocked because its
        address exactly matches an older store whose data is not ready
        (Precise event). Unit: cpu_atom]
  machine_clears.disambiguation
       [Counts the number of machine clears due to memory ordering in which an
        internal load passes an older store within the same CPU. Unit:
        cpu_atom]
  machine_clears.mrn_nuke
       [Counts the number of machines clears due to memory renaming. Unit:
        cpu_atom]
  machine_clears.page_fault
       [Counts the number of machine clears due to a page fault. Counts both
        I-Side and D-Side (Loads/Stores) page faults. A page fault occurs when
        either the page is not present, or an access violation occurs. Unit:
        cpu_atom]
  machine_clears.slow
       [Counts the number of machine clears that flush the pipeline and
        restart the machine with the use of microcode due to SMC,
        MEMORY_ORDERING, FP_ASSISTS, PAGE_FAULT, DISAMBIGUATION, and
        FPC_VIRTUAL_TRAP. Unit: cpu_atom]
  machine_clears.smc
       [Counts the number of machine clears due to program modifying data
        (self modifying code) within 1K of a recently fetched code page. Unit:
        cpu_atom]
  serialization.non_c01_ms_scb
       [Counts the number of issue slots not consumed by the backend due to a
        micro-sequencer (MS) scoreboard, which stalls the front-end from
        issuing from the UROM until a specified older uop retires. Unit:
        cpu_atom]
  topdown_bad_speculation.all
       [Counts the total number of issue slots that were not consumed by the
        backend because allocation is stalled due to a mispredicted jump or a
        machine clear. Unit: cpu_atom]
  topdown_bad_speculation.fastnuke
       [Counts the number of issue slots every cycle that were not consumed by
        the backend due to fast nukes such as memory ordering and memory
        disambiguation machine clears. Unit: cpu_atom]
  topdown_bad_speculation.machine_clears
       [Counts the total number of issue slots that were not consumed by the
        backend because allocation is stalled due to a machine clear (nuke) of
        any kind including memory ordering and memory disambiguation. Unit:
        cpu_atom]
  topdown_bad_speculation.mispredict
       [Counts the number of issue slots every cycle that were not consumed by
        the backend due to branch mispredicts. Unit: cpu_atom]
  topdown_bad_speculation.nuke
       [Counts the number of issue slots every cycle that were not consumed by
        the backend due to a machine clear (nuke). Unit: cpu_atom]
  topdown_be_bound.all
       [Counts the total number of issue slots every cycle that were not
        consumed by the backend due to backend stalls. Unit: cpu_atom]
  topdown_be_bound.alloc_restrictions
       [Counts the number of issue slots every cycle that were not consumed by
        the backend due to certain allocation restrictions. Unit: cpu_atom]
  topdown_be_bound.mem_scheduler
       [Counts the number of issue slots every cycle that were not consumed by
        the backend due to memory reservation stalls in which a scheduler is
        not able to accept uops. Unit: cpu_atom]
  topdown_be_bound.non_mem_scheduler
       [Counts the number of issue slots every cycle that were not consumed by
        the backend due to IEC or FPC RAT stalls, which can be due to FIQ or
        IEC reservation stalls in which the integer, floating point or SIMD
        scheduler is not able to accept uops. Unit: cpu_atom]
  topdown_be_bound.register
       [Counts the number of issue slots every cycle that were not consumed by
        the backend due to the physical register file unable to accept an
        entry (marble stalls). Unit: cpu_atom]
  topdown_be_bound.reorder_buffer
       [Counts the number of issue slots every cycle that were not consumed by
        the backend due to the reorder buffer being full (ROB stalls). Unit:
        cpu_atom]
  topdown_be_bound.serialization
       [Counts the number of issue slots every cycle that were not consumed by
        the backend due to scoreboards from the instruction queue (IQ), jump
        execution unit (JEU), or microcode sequencer (MS). Unit: cpu_atom]
  topdown_fe_bound.all
       [Counts the total number of issue slots every cycle that were not
        consumed by the backend due to frontend stalls. Unit: cpu_atom]
  topdown_fe_bound.branch_detect
       [Counts the number of issue slots every cycle that were not delivered
        by the frontend due to BACLEARS. Unit: cpu_atom]
  topdown_fe_bound.branch_resteer
       [Counts the number of issue slots every cycle that were not delivered
        by the frontend due to BTCLEARS. Unit: cpu_atom]
  topdown_fe_bound.cisc
       [Counts the number of issue slots every cycle that were not delivered
        by the frontend due to the microcode sequencer (MS). Unit: cpu_atom]
  topdown_fe_bound.decode
       [Counts the number of issue slots every cycle that were not delivered
        by the frontend due to decode stalls. Unit: cpu_atom]
  topdown_fe_bound.frontend_bandwidth
       [Counts the number of issue slots every cycle that were not delivered
        by the frontend due to frontend bandwidth restrictions due to decode,
        predecode, cisc, and other limitations. Unit: cpu_atom]
  topdown_fe_bound.frontend_latency
       [Counts the number of issue slots every cycle that were not delivered
        by the frontend due to a latency related stalls including BACLEARs,
        BTCLEARs, ITLB misses, and ICache misses. Unit: cpu_atom]
  topdown_fe_bound.itlb
       [Counts the number of issue slots every cycle that were not delivered
        by the frontend due to ITLB misses. Unit: cpu_atom]
  topdown_fe_bound.other
       [Counts the number of issue slots every cycle that were not delivered
        by the frontend due to other common frontend stalls not categorized.
        Unit: cpu_atom]
  topdown_fe_bound.predecode
       [Counts the number of issue slots every cycle that were not delivered
        by the frontend due to wrong predecodes. Unit: cpu_atom]
  topdown_retiring.all
       [Counts the total number of consumed retirement slots (Precise event).
        Unit: cpu_atom]
  uops_retired.all
       [Counts the total number of uops retired (Precise event). Unit:
        cpu_atom]
  uops_retired.idiv
       [Counts the number of integer divide uops retired (Precise event).
        Unit: cpu_atom]
  uops_retired.ms
       [Counts the number of uops that are from complex flows issued by the
        micro-sequencer (MS) (Precise event). Unit: cpu_atom]
  uops_retired.x87
       [Counts the number of x87 uops retired, includes those in MS flows
        (Precise event). Unit: cpu_atom]
  arith.div_active
       [Cycles when divide unit is busy executing divide or square root
        operations. Unit: cpu_core]
  arith.idiv_active
       [This event counts the cycles the integer divider is busy. Unit:
        cpu_core]
  assists.any
       [Number of occurrences where a microcode assist is invoked by hardware.
        Unit: cpu_core]
  br_inst_retired.all_branches
       [All branch instructions retired (Precise event). Unit: cpu_core]
  br_inst_retired.cond
       [Conditional branch instructions retired (Precise event). Unit:
        cpu_core]
  br_inst_retired.cond_ntaken
       [Not taken branch instructions retired (Precise event). Unit: cpu_core]
  br_inst_retired.cond_taken
       [Taken conditional branch instructions retired (Precise event). Unit:
        cpu_core]
  br_inst_retired.far_branch
       [Far branch instructions retired (Precise event). Unit: cpu_core]
  br_inst_retired.indirect
       [Indirect near branch instructions retired (excluding returns) (Precise
        event). Unit: cpu_core]
  br_inst_retired.near_call
       [Direct and indirect near call instructions retired (Precise event).
        Unit: cpu_core]
  br_inst_retired.near_return
       [Return instructions retired (Precise event). Unit: cpu_core]
  br_inst_retired.near_taken
       [Taken branch instructions retired (Precise event). Unit: cpu_core]
  br_misp_retired.all_branches
       [All mispredicted branch instructions retired (Precise event). Unit:
        cpu_core]
  br_misp_retired.cond
       [Mispredicted conditional branch instructions retired (Precise event).
        Unit: cpu_core]
  br_misp_retired.cond_ntaken
       [Mispredicted non-taken conditional branch instructions retired
        (Precise event). Unit: cpu_core]
  br_misp_retired.cond_taken
       [number of branch instructions retired that were mispredicted and taken
        (Precise event). Unit: cpu_core]
  br_misp_retired.indirect
       [Miss-predicted near indirect branch instructions retired (excluding
        returns) (Precise event). Unit: cpu_core]
  br_misp_retired.indirect_call
       [Mispredicted indirect CALL retired (Precise event). Unit: cpu_core]
  br_misp_retired.near_taken
       [Number of near branch instructions retired that were mispredicted and
        taken (Precise event). Unit: cpu_core]
  br_misp_retired.ret
       [This event counts the number of mispredicted ret instructions retired.
        Non PEBS (Precise event). Unit: cpu_core]
  cpu_clk_unhalted.c01
       [Core clocks when the thread is in the C0.1 light-weight slower wakeup
        time but more power saving optimized state. Unit: cpu_core]
  cpu_clk_unhalted.c02
       [Core clocks when the thread is in the C0.2 light-weight faster wakeup
        time but less power saving optimized state. Unit: cpu_core]
  cpu_clk_unhalted.c0_wait
       [Core clocks when the thread is in the C0.1 or C0.2 or running a PAUSE
        in C0 ACPI state. Unit: cpu_core]
  cpu_clk_unhalted.distributed
       [Cycle counts are evenly distributed between active threads in the
        Core. Unit: cpu_core]
  cpu_clk_unhalted.one_thread_active
       [Core crystal clock cycles when this thread is unhalted and the other
        thread is halted. Unit: cpu_core]
  cpu_clk_unhalted.pause
       [CPU_CLK_UNHALTED.PAUSE. Unit: cpu_core]
  cpu_clk_unhalted.pause_inst
       [CPU_CLK_UNHALTED.PAUSE_INST. Unit: cpu_core]
  cpu_clk_unhalted.ref_distributed
       [Core crystal clock cycles. Cycle counts are evenly distributed between
        active threads in the Core. Unit: cpu_core]
  cpu_clk_unhalted.ref_tsc
       [Reference cycles when the core is not in halt state. Unit: cpu_core]
  cpu_clk_unhalted.ref_tsc_p
       [Reference cycles when the core is not in halt state. Unit: cpu_core]
  cpu_clk_unhalted.thread
       [Core cycles when the thread is not in halt state. Unit: cpu_core]
  cpu_clk_unhalted.thread_p
       [Thread cycles when thread is not in halt state. Unit: cpu_core]
  cycle_activity.cycles_l1d_miss
       [Cycles while L1 cache miss demand load is outstanding. Unit: cpu_core]
  cycle_activity.cycles_l2_miss
       [Cycles while L2 cache miss demand load is outstanding. Unit: cpu_core]
  cycle_activity.cycles_mem_any
       [Cycles while memory subsystem has an outstanding load. Unit: cpu_core]
  cycle_activity.stalls_l1d_miss
       [Execution stalls while L1 cache miss demand load is outstanding. Unit:
        cpu_core]
  cycle_activity.stalls_l2_miss
       [Execution stalls while L2 cache miss demand load is outstanding. Unit:
        cpu_core]
  cycle_activity.stalls_total
       [Total execution stalls. Unit: cpu_core]
  exe_activity.1_ports_util
       [Cycles total of 1 uop is executed on all ports and Reservation Station
        was not empty. Unit: cpu_core]
  exe_activity.2_ports_util
       [Cycles total of 2 uops are executed on all ports and Reservation
        Station was not empty. Unit: cpu_core]
  exe_activity.3_ports_util
       [Cycles total of 3 uops are executed on all ports and Reservation
        Station was not empty. Unit: cpu_core]
  exe_activity.4_ports_util
       [Cycles total of 4 uops are executed on all ports and Reservation
        Station was not empty. Unit: cpu_core]
  exe_activity.bound_on_loads
       [Execution stalls while memory subsystem has an outstanding load. Unit:
        cpu_core]
  exe_activity.bound_on_stores
       [Cycles where the Store Buffer was full and no loads caused an
        execution stall. Unit: cpu_core]
  exe_activity.exe_bound_0_ports
       [Cycles no uop executed while RS was not empty, the SB was not full and
        there was no outstanding load. Unit: cpu_core]
  inst_decoded.decoders
       [Instruction decoders utilized in a cycle. Unit: cpu_core]
  inst_retired.any
       [Number of instructions retired. Fixed Counter - architectural event
        (Precise event). Unit: cpu_core]
  inst_retired.any_p
       [Number of instructions retired. General Counter - architectural event
        (Precise event). Unit: cpu_core]
  inst_retired.macro_fused
       [INST_RETIRED.MACRO_FUSED. Unit: cpu_core]
  inst_retired.nop
       [Retired NOP instructions. Unit: cpu_core]
  inst_retired.prec_dist
       [Precise instruction retired with PEBS precise-distribution (Precise
        event). Unit: cpu_core]
  inst_retired.rep_iteration
       [Iterations of Repeat string retired instructions. Unit: cpu_core]
  int_misc.clear_resteer_cycles
       [Counts cycles after recovery from a branch misprediction or machine
        clear till the first uop is issued from the resteered path. Unit:
        cpu_core]
  int_misc.clears_count
       [Clears speculative count. Unit: cpu_core]
  int_misc.recovery_cycles
       [Core cycles the allocator was stalled due to recovery from earlier
        clear event for this thread. Unit: cpu_core]
  int_misc.unknown_branch_cycles
       [Bubble cycles of BAClear (Unknown Branch). Unit: cpu_core]
  int_misc.uop_dropping
       [TMA slots where uops got dropped. Unit: cpu_core]
  int_vec_retired.128bit
       [INT_VEC_RETIRED.128BIT. Unit: cpu_core]
  int_vec_retired.256bit
       [INT_VEC_RETIRED.256BIT. Unit: cpu_core]
  int_vec_retired.add_128
       [integer ADD, SUB, SAD 128-bit vector instructions. Unit: cpu_core]
  int_vec_retired.add_256
       [integer ADD, SUB, SAD 256-bit vector instructions. Unit: cpu_core]
  int_vec_retired.mul_256
       [INT_VEC_RETIRED.MUL_256. Unit: cpu_core]
  int_vec_retired.shuffles
       [INT_VEC_RETIRED.SHUFFLES. Unit: cpu_core]
  int_vec_retired.vnni_128
       [INT_VEC_RETIRED.VNNI_128. Unit: cpu_core]
  int_vec_retired.vnni_256
       [INT_VEC_RETIRED.VNNI_256. Unit: cpu_core]
  ld_blocks.address_alias
       [False dependencies in MOB due to partial compare on address. Unit:
        cpu_core]
  ld_blocks.no_sr
       [The number of times that split load operations are temporarily blocked
        because all resources for handling the split accesses are in use.
        Unit: cpu_core]
  ld_blocks.store_forward
       [Loads blocked due to overlapping with a preceding store that cannot be
        forwarded. Unit: cpu_core]
  load_hit_prefetch.swpf
       [Counts the number of demand load dispatches that hit L1D fill buffer
        (FB) allocated for software prefetch. Unit: cpu_core]
  lsd.cycles_active
       [Cycles Uops delivered by the LSD, but didn't come from the decoder.
        Unit: cpu_core]
  lsd.cycles_ok
       [Cycles optimal number of Uops delivered by the LSD, but did not come
        from the decoder. Unit: cpu_core]
  lsd.uops
       [Number of Uops delivered by the LSD. Unit: cpu_core]
  machine_clears.count
       [Number of machine clears (nukes) of any type. Unit: cpu_core]
  machine_clears.smc
       [Self-modifying code (SMC) detected. Unit: cpu_core]
  misc2_retired.lfence
       [LFENCE instructions retired. Unit: cpu_core]
  misc_retired.lbr_inserts
       [Increments whenever there is an update to the LBR array. Unit:
        cpu_core]
  resource_stalls.sb
       [Cycles stalled due to no store buffers available. (not including
        draining form sync). Unit: cpu_core]
  resource_stalls.scoreboard
       [Counts cycles where the pipeline is stalled due to serializing
        operations. Unit: cpu_core]
  topdown.backend_bound_slots
       [TMA slots where no uops were being issued due to lack of back-end
        resources. Unit: cpu_core]
  topdown.bad_spec_slots
       [TMA slots wasted due to incorrect speculations. Unit: cpu_core]
  topdown.br_mispredict_slots
       [TMA slots wasted due to incorrect speculation by branch
        mispredictions. Unit: cpu_core]
  topdown.memory_bound_slots
       [TOPDOWN.MEMORY_BOUND_SLOTS. Unit: cpu_core]
  topdown.slots
       [TMA slots available for an unhalted logical processor. Fixed counter -
        architectural event. Unit: cpu_core]
  topdown.slots_p
       [TMA slots available for an unhalted logical processor. General counter
        - architectural event. Unit: cpu_core]
  uops_decoded.dec0_uops
       [UOPS_DECODED.DEC0_UOPS. Unit: cpu_core]
  uops_dispatched.port_0
       [Uops executed on port 0. Unit: cpu_core]
  uops_dispatched.port_1
       [Uops executed on port 1. Unit: cpu_core]
  uops_dispatched.port_2_3_10
       [Uops executed on ports 2, 3 and 10. Unit: cpu_core]
  uops_dispatched.port_4_9
       [Uops executed on ports 4 and 9. Unit: cpu_core]
  uops_dispatched.port_5_11
       [Uops executed on ports 5 and 11. Unit: cpu_core]
  uops_dispatched.port_6
       [Uops executed on port 6. Unit: cpu_core]
  uops_dispatched.port_7_8
       [Uops executed on ports 7 and 8. Unit: cpu_core]
  uops_executed.core_cycles_ge_1
       [Cycles at least 1 micro-op is executed from any thread on physical
        core. Unit: cpu_core]
  uops_executed.core_cycles_ge_2
       [Cycles at least 2 micro-op is executed from any thread on physical
        core. Unit: cpu_core]
  uops_executed.core_cycles_ge_3
       [Cycles at least 3 micro-op is executed from any thread on physical
        core. Unit: cpu_core]
  uops_executed.core_cycles_ge_4
       [Cycles at least 4 micro-op is executed from any thread on physical
        core. Unit: cpu_core]
  uops_executed.cycles_ge_1
       [Cycles where at least 1 uop was executed per-thread. Unit: cpu_core]
  uops_executed.cycles_ge_2
       [Cycles where at least 2 uops were executed per-thread. Unit: cpu_core]
  uops_executed.cycles_ge_3
       [Cycles where at least 3 uops were executed per-thread. Unit: cpu_core]
  uops_executed.cycles_ge_4
       [Cycles where at least 4 uops were executed per-thread. Unit: cpu_core]
  uops_executed.stalls
       [Counts number of cycles no uops were dispatched to be executed on this
        thread. Unit: cpu_core]
  uops_executed.thread
       [Counts the number of uops to be executed per-thread each cycle. Unit:
        cpu_core]
  uops_executed.x87
       [Counts the number of x87 uops dispatched. Unit: cpu_core]
  uops_issued.any
       [Uops that RAT issues to RS. Unit: cpu_core]
  uops_retired.cycles
       [Cycles with retired uop(s). Unit: cpu_core]
  uops_retired.heavy
       [Retired uops except the last uop of each instruction. Unit: cpu_core]
  uops_retired.ms
       [UOPS_RETIRED.MS. Unit: cpu_core]
  uops_retired.slots
       [Retirement slots used. Unit: cpu_core]
  uops_retired.stalls
       [Cycles without actually retired uops. Unit: cpu_core]

uncore interconnect:
  unc_arb_coh_trk_requests.all
       [Number of requests allocated in Coherency Tracker. Unit: uncore_arb]
  unc_arb_dat_occupancy.all
       [Each cycle counts number of any coherent request at memory controller
        that were issued by any core. Unit: uncore_arb]
  unc_arb_dat_occupancy.rd
       [Each cycle counts number of coherent reads pending on data return from
        memory controller that were issued by any core. Unit: uncore_arb]
  unc_arb_req_trk_occupancy.drd
       [Each cycle count number of 'valid' coherent Data Read entries . Such
        entry is defined as valid when it is allocated till deallocation.
        Doesn't include prefetches [This event is alias to
        UNC_ARB_TRK_OCCUPANCY.RD]. Unit: uncore_arb]
  unc_arb_req_trk_request.drd
       [Number of all coherent Data Read entries. Doesn't include prefetches
        [This event is alias to UNC_ARB_TRK_REQUESTS.RD]. Unit: uncore_arb]
  unc_arb_trk_occupancy.all
       [Each cycle counts number of all outgoing valid entries in ReqTrk. Such
        entry is defined as valid from its allocation in ReqTrk till
        deallocation. Accounts for Coherent and non-coherent traffic. Unit:
        uncore_arb]
  unc_arb_trk_occupancy.rd
       [Each cycle count number of 'valid' coherent Data Read entries . Such
        entry is defined as valid when it is allocated till deallocation.
        Doesn't include prefetches [This event is alias to
        UNC_ARB_REQ_TRK_OCCUPANCY.DRD]. Unit: uncore_arb]
  unc_arb_trk_requests.all
       [Counts the number of coherent and in-coherent requests initiated by IA
        cores, processor graphic units, or LLC. Unit: uncore_arb]
  unc_arb_trk_requests.rd
       [Number of all coherent Data Read entries. Doesn't include prefetches
        [This event is alias to UNC_ARB_REQ_TRK_REQUEST.DRD]. Unit: uncore_arb]

uncore memory:
  unc_m_act_count_rd
       [ACT command for a read request sent to DRAM. Unit: uncore_imc]
  unc_m_act_count_total
       [ACT command sent to DRAM. Unit: uncore_imc]
  unc_m_act_count_wr
       [ACT command for a write request sent to DRAM. Unit: uncore_imc]
  unc_m_cas_count_rd
       [Read CAS command sent to DRAM. Unit: uncore_imc]
  unc_m_cas_count_wr
       [Write CAS command sent to DRAM. Unit: uncore_imc]
  unc_m_clockticks
       [Number of clocks. Unit: uncore_imc]
  unc_m_dram_page_empty_rd
       [incoming read request page status is Page Empty. Unit: uncore_imc]
  unc_m_dram_page_empty_wr
       [incoming write request page status is Page Empty. Unit: uncore_imc]
  unc_m_dram_page_hit_rd
       [incoming read request page status is Page Hit. Unit: uncore_imc]
  unc_m_dram_page_hit_wr
       [incoming write request page status is Page Hit. Unit: uncore_imc]
  unc_m_dram_page_miss_rd
       [incoming read request page status is Page Miss. Unit: uncore_imc]
  unc_m_dram_page_miss_wr
       [incoming write request page status is Page Miss. Unit: uncore_imc]
  unc_m_dram_thermal_hot
       [Any Rank at Hot state. Unit: uncore_imc]
  unc_m_dram_thermal_warm
       [Any Rank at Warm state. Unit: uncore_imc]
  unc_m_pre_count_idle
       [PRE command sent to DRAM due to page table idle timer expiration.
        Unit: uncore_imc]
  unc_m_pre_count_page_miss
       [PRE command sent to DRAM for a read/write request. Unit: uncore_imc]
  unc_m_prefetch_rd
       [Incoming read prefetch request from IA. Unit: uncore_imc]
  unc_m_vc0_requests_rd
       [Incoming VC0 read request. Unit: uncore_imc]
  unc_m_vc0_requests_wr
       [Incoming VC0 write request. Unit: uncore_imc]
  unc_m_vc1_requests_rd
       [Incoming VC1 read request. Unit: uncore_imc]
  unc_m_vc1_requests_wr
       [Incoming VC1 write request. Unit: uncore_imc]
  unc_mc0_rdcas_count_freerun
       [Counts every 64B read request entering the Memory Controller 0 to DRAM
        (sum of all channels). Unit: uncore_imc_free_running_0]
  unc_mc0_wrcas_count_freerun
       [Counts every 64B write request entering the Memory Controller 0 to
        DRAM (sum of all channels). Each write request counts as a new request
        incrementing this counter. However, same cache line write requests
        (both full and partial) are combined to a single 64 byte data transfer
        to DRAM. Unit: uncore_imc_free_running_0]

uncore other:
  unc_clock.socket
       [This 48-bit fixed counter counts the UCLK cycles. Unit: uncore_clock]

virtual memory:
  dtlb_load_misses.walk_completed
       [Counts the number of page walks completed due to load DTLB misses to
        any page size. Unit: cpu_atom]
  dtlb_store_misses.walk_completed
       [Counts the number of page walks completed due to store DTLB misses to
        any page size. Unit: cpu_atom]
  itlb_misses.miss_caused_walk
       [Counts the number of page walks initiated by a instruction fetch that
        missed the first and second level TLBs. Unit: cpu_atom]
  itlb_misses.pde_cache_miss
       [Counts the number of page walks due to an instruction fetch that miss
        the PDE (Page Directory Entry) cache. Unit: cpu_atom]
  itlb_misses.walk_completed
       [Counts the number of page walks completed due to instruction fetch
        misses to any page size. Unit: cpu_atom]
  ld_head.dtlb_miss_at_ret
       [Counts the number of cycles that the head (oldest load) of the load
        buffer and retirement are both stalled due to a DTLB miss. Unit:
        cpu_atom]
  dtlb_load_misses.stlb_hit
       [Loads that miss the DTLB and hit the STLB. Unit: cpu_core]
  dtlb_load_misses.walk_active
       [Cycles when at least one PMH is busy with a page walk for a demand
        load. Unit: cpu_core]
  dtlb_load_misses.walk_completed
       [Load miss in all TLB levels causes a page walk that completes. (All
        page sizes). Unit: cpu_core]
  dtlb_load_misses.walk_completed_1g
       [Page walks completed due to a demand data load to a 1G page. Unit:
        cpu_core]
  dtlb_load_misses.walk_completed_2m_4m
       [Page walks completed due to a demand data load to a 2M/4M page. Unit:
        cpu_core]
  dtlb_load_misses.walk_completed_4k
       [Page walks completed due to a demand data load to a 4K page. Unit:
        cpu_core]
  dtlb_load_misses.walk_pending
       [Number of page walks outstanding for a demand load in the PMH each
        cycle. Unit: cpu_core]
  dtlb_store_misses.stlb_hit
       [Stores that miss the DTLB and hit the STLB. Unit: cpu_core]
  dtlb_store_misses.walk_active
       [Cycles when at least one PMH is busy with a page walk for a store.
        Unit: cpu_core]
  dtlb_store_misses.walk_completed
       [Store misses in all TLB levels causes a page walk that completes. (All
        page sizes). Unit: cpu_core]
  dtlb_store_misses.walk_completed_1g
       [Page walks completed due to a demand data store to a 1G page. Unit:
        cpu_core]
  dtlb_store_misses.walk_completed_2m_4m
       [Page walks completed due to a demand data store to a 2M/4M page. Unit:
        cpu_core]
  dtlb_store_misses.walk_completed_4k
       [Page walks completed due to a demand data store to a 4K page. Unit:
        cpu_core]
  dtlb_store_misses.walk_pending
       [Number of page walks outstanding for a store in the PMH each cycle.
        Unit: cpu_core]
  itlb_misses.stlb_hit
       [Instruction fetch requests that miss the ITLB and hit the STLB. Unit:
        cpu_core]
  itlb_misses.walk_active
       [Cycles when at least one PMH is busy with a page walk for code
        (instruction fetch) request. Unit: cpu_core]
  itlb_misses.walk_completed
       [Code miss in all TLB levels causes a page walk that completes. (All
        page sizes). Unit: cpu_core]
  itlb_misses.walk_completed_2m_4m
       [Code miss in all TLB levels causes a page walk that completes.
        (2M/4M). Unit: cpu_core]
  itlb_misses.walk_completed_4k
       [Code miss in all TLB levels causes a page walk that completes. (4K).
        Unit: cpu_core]
  itlb_misses.walk_pending
       [Number of page walks outstanding for an outstanding code request in
        the PMH each cycle. Unit: cpu_core]
  rNNN                                               [Raw hardware event descriptor]
  cpu_atom/t1=v1[,t2=v2,t3 ...]/modifier             [Raw hardware event descriptor]
       [(see 'man perf-list' on how to encode it)]
  mem:<addr>[/len][:access]                          [Hardware breakpoint]

Metric Groups:

Backend: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_core_bound
       [This metric represents fraction of slots where Core non-memory issues
        were of a bottleneck]
  tma_info_core_ilp
       [Instruction-Level-Parallelism (average number of uops executed when
        there is execution) per-core]
  tma_info_memory_l2mpki
       [L2 cache true misses per kilo instruction for retired demand loads]
  tma_memory_bound
       [This metric represents fraction of slots the Memory subsystem within
        the Backend was a bottleneck]

Bad: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_info_bad_spec_branch_misprediction_cost
       [Branch Misprediction Cost: Fraction of TMA slots wasted per
        non-speculative branch misprediction (retired JEClear)]
  tma_info_bad_spec_ipmisp_cond_ntaken
       [Instructions per retired mispredicts for conditional non-taken
        branches (lower number means higher occurrence rate)]
  tma_info_bad_spec_ipmisp_cond_taken
       [Instructions per retired mispredicts for conditional taken branches
        (lower number means higher occurrence rate)]
  tma_info_bad_spec_ipmisp_indirect
       [Instructions per retired mispredicts for indirect CALL or JMP branches
        (lower number means higher occurrence rate)]
  tma_info_bad_spec_ipmisp_ret
       [Instructions per retired mispredicts for return branches (lower number
        means higher occurrence rate)]
  tma_info_bad_spec_ipmispredict
       [Number of Instructions per non-speculative Branch Misprediction
        (JEClear) (lower number means higher occurrence rate)]
  tma_info_bottleneck_mispredictions
       [Total pipeline cost of Branch Misprediction related bottlenecks]
  tma_info_branches_callret
       [Fraction of branches that are CALL or RET]
  tma_info_branches_cond_nt
       [Fraction of branches that are non-taken conditionals]
  tma_info_branches_cond_tk
       [Fraction of branches that are taken conditionals]
  tma_info_branches_jump
       [Fraction of branches that are unconditional (direct or indirect) jumps]
  tma_info_branches_other_branches
       [Fraction of branches of other types (not individually covered by other
        metrics in Info.Branches group)]

BadSpec:
  tma_branch_mispredicts
       [This metric represents fraction of slots the CPU has wasted due to
        Branch Misprediction]
  tma_clears_resteers
       [This metric represents fraction of cycles the CPU was stalled due to
        Branch Resteers as a result of Machine Clears]
  tma_info_bad_spec_ipmispredict
       [Number of Instructions per non-speculative Branch Misprediction
        (JEClear) (lower number means higher occurrence rate)]
  tma_info_bottleneck_mispredictions
       [Total pipeline cost of Branch Misprediction related bottlenecks]
  tma_machine_clears
       [This metric represents fraction of slots the CPU has wasted due to
        Machine Clears]
  tma_mispredicts_resteers
       [This metric represents fraction of cycles the CPU was stalled due to
        Branch Resteers as a result of Branch Misprediction at execution stage]

BigFoot: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_icache_misses
       [This metric represents fraction of cycles the CPU was stalled due to
        instruction cache misses]
  tma_info_bottleneck_big_code
       [Total pipeline cost of instruction fetch related bottlenecks by large
        code footprint programs (i-side cache; TLB and BTB misses)]
  tma_itlb_misses
       [This metric represents fraction of cycles the CPU was stalled due to
        Instruction TLB (ITLB) misses]
  tma_unknown_branches
       [This metric represents fraction of cycles the CPU was stalled due to
        new branch address clears]

BrMispredicts: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_branch_mispredicts
       [This metric represents fraction of slots the CPU has wasted due to
        Branch Misprediction]
  tma_info_bad_spec_branch_misprediction_cost
       [Branch Misprediction Cost: Fraction of TMA slots wasted per
        non-speculative branch misprediction (retired JEClear)]
  tma_info_bad_spec_ipmisp_cond_ntaken
       [Instructions per retired mispredicts for conditional non-taken
        branches (lower number means higher occurrence rate)]
  tma_info_bad_spec_ipmisp_cond_taken
       [Instructions per retired mispredicts for conditional taken branches
        (lower number means higher occurrence rate)]
  tma_info_bad_spec_ipmisp_indirect
       [Instructions per retired mispredicts for indirect CALL or JMP branches
        (lower number means higher occurrence rate)]
  tma_info_bad_spec_ipmisp_ret
       [Instructions per retired mispredicts for return branches (lower number
        means higher occurrence rate)]
  tma_info_bad_spec_ipmispredict
       [Number of Instructions per non-speculative Branch Misprediction
        (JEClear) (lower number means higher occurrence rate)]
  tma_info_bottleneck_mispredictions
       [Total pipeline cost of Branch Misprediction related bottlenecks]
  tma_mispredicts_resteers
       [This metric represents fraction of cycles the CPU was stalled due to
        Branch Resteers as a result of Branch Misprediction at execution stage]

Branches: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_info_branches_callret
       [Fraction of branches that are CALL or RET]
  tma_info_branches_cond_nt
       [Fraction of branches that are non-taken conditionals]
  tma_info_branches_cond_tk
       [Fraction of branches that are taken conditionals]
  tma_info_branches_jump
       [Fraction of branches that are unconditional (direct or indirect) jumps]
  tma_info_branches_other_branches
       [Fraction of branches of other types (not individually covered by other
        metrics in Info.Branches group)]
  tma_info_inst_mix_bptkbranch
       [Branch instructions per taken branch]
  tma_info_inst_mix_ipbranch
       [Instructions per Branch (lower number means higher occurrence rate)]
  tma_info_inst_mix_ipcall
       [Instructions per (near) call (lower number means higher occurrence
        rate)]
  tma_info_inst_mix_iptb
       [Instruction per taken branch]
  tma_info_system_ipfarbranch
       [Instructions per Far Branch ( Far Branches apply upon transition from
        application to operating system, handling interrupts, exceptions)
        [lower number means higher occurrence rate]]
  tma_info_thread_uptb
       [Instruction per taken branch]

CacheMisses: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_info_memory_fb_hpki
       [Fill Buffer (FB) hits per kilo instructions for retired demand loads
        (L1D misses that merge into ongoing miss-handling entries)]
  tma_info_memory_l1mpki
       [L1 cache true misses per kilo instruction for retired demand loads]
  tma_info_memory_l1mpki_load
       [L1 cache true misses per kilo instruction for all demand loads
        (including speculative)]
  tma_info_memory_l2hpki_all
       [L2 cache hits per kilo instruction for all request types (including
        speculative)]
  tma_info_memory_l2hpki_load
       [L2 cache hits per kilo instruction for all demand loads (including
        speculative)]
  tma_info_memory_l2mpki
       [L2 cache true misses per kilo instruction for retired demand loads]
  tma_info_memory_l2mpki_all
       [L2 cache ([RKL+] true) misses per kilo instruction for all request
        types (including speculative)]
  tma_info_memory_l2mpki_load
       [L2 cache ([RKL+] true) misses per kilo instruction for all demand
        loads (including speculative)]
  tma_info_memory_l3mpki
       [L3 cache true misses per kilo instruction for retired demand loads]
  tma_l1_bound
       [This metric estimates how often the CPU was stalled without loads
        missing the L1 data cache]
  tma_l2_bound
       [This metric estimates how often the CPU was stalled due to L2 cache
        accesses by loads]
  tma_l3_bound
       [This metric estimates how often the CPU was stalled due to loads
        accesses to L3 cache or contended with a sibling Core]

CodeGen: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_info_branches_cond_nt
       [Fraction of branches that are non-taken conditionals]
  tma_info_branches_cond_tk
       [Fraction of branches that are taken conditionals]

Compute: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_core_bound
       [This metric represents fraction of slots where Core non-memory issues
        were of a bottleneck]
  tma_fp_scalar
       [This metric approximates arithmetic floating-point (FP) scalar uops
        fraction the CPU has retired]
  tma_fp_vector
       [This metric approximates arithmetic floating-point (FP) vector uops
        fraction the CPU has retired aggregated across all vector widths]
  tma_fp_vector_128b
       [This metric approximates arithmetic FP vector uops fraction the CPU
        has retired for 128-bit wide vectors]
  tma_fp_vector_256b
       [This metric approximates arithmetic FP vector uops fraction the CPU
        has retired for 256-bit wide vectors]
  tma_int_vector_128b
       [This metric represents 128-bit vector Integer ADD/SUB/SAD or VNNI
        (Vector Neural Network Instructions) uops fraction the CPU has retired]
  tma_int_vector_256b
       [This metric represents 256-bit vector Integer ADD/SUB/SAD or VNNI
        (Vector Neural Network Instructions) uops fraction the CPU has retired]
  tma_port_0
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution port 0 ([SNB+] ALU; [HSW+] ALU and 2nd branch)]
  tma_x87_use
       [This metric serves as an approximation of legacy x87 usage]

Cor: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_info_botlnk_l0_core_bound_likely
       [Probability of Core Bound bottleneck hidden by SMT-profiling artifacts]
  tma_info_core_fp_arith_utilization
       [Actual per-core usage of the Floating Point non-X87 execution units
        (regardless of precision or vector-width)]
  tma_info_core_ilp
       [Instruction-Level-Parallelism (average number of uops executed when
        there is execution) per-core]
  tma_info_pipeline_execute
       [Instruction-Level-Parallelism (average number of uops executed when
        there is execution) per-thread]
  tma_info_system_gflops
       [Giga Floating Point Operations Per Second]
  tma_info_thread_execute_per_issue
       [The ratio of Executed- by Issued-Uops]

DSB: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_dsb
       [This metric represents Core fraction of cycles in which CPU was likely
        limited due to DSB (decoded uop cache) fetch pipeline]
  tma_info_frontend_dsb_coverage
       [Fraction of Uops delivered by the DSB (aka Decoded ICache; or Uop
        Cache)]

DSBmiss: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_decoder0_alone
       [This metric represents fraction of cycles where decoder-0 was the only
        active decoder]
  tma_dsb_switches
       [This metric represents fraction of cycles the CPU was stalled due to
        switches from DSB to MITE pipelines]
  tma_info_botlnk_l2_dsb_misses
       [Total pipeline cost of DSB (uop cache) misses - subset of the
        Instruction_Fetch_BW Bottleneck]
  tma_info_frontend_dsb_switch_cost
       [Average number of cycles of a switch from the DSB fetch-unit to MITE
        fetch unit - see DSB_Switches tree node for details]
  tma_info_frontend_ipdsb_miss_ret
       [Instructions per non-speculative DSB miss (lower number means higher
        occurrence rate)]
  tma_mite
       [This metric represents Core fraction of cycles in which CPU was likely
        limited due to the MITE pipeline (the legacy decode pipeline)]

DataSharing: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_contested_accesses
       [This metric estimates fraction of cycles while the memory subsystem
        was handling synchronizations due to contested accesses]
  tma_false_sharing
       [This metric roughly estimates how often CPU was handling
        synchronizations due to False Sharing]

Default:
  tma_backend_bound
       [This category represents fraction of slots where no uops are being
        delivered due to a lack of required resources for accepting new uops
        in the Backend]
  tma_backend_bound_aux
       [Counts the total number of issue slots that were not consumed by the
        backend due to backend stalls]
  tma_bad_speculation
       [This category represents fraction of slots wasted due to incorrect
        speculations]
  tma_frontend_bound
       [This category represents fraction of slots where the processor's
        Frontend undersupplies its Backend]
  tma_retiring
       [This category represents fraction of slots utilized by useful work
        i.e. issued uops that eventually get retired]

Fed: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_info_botlnk_l2_dsb_misses
       [Total pipeline cost of DSB (uop cache) misses - subset of the
        Instruction_Fetch_BW Bottleneck]
  tma_info_botlnk_l2_ic_misses
       [Total pipeline cost of Instruction Cache misses - subset of the
        Big_Code Bottleneck]
  tma_info_bottleneck_big_code
       [Total pipeline cost of instruction fetch related bottlenecks by large
        code footprint programs (i-side cache; TLB and BTB misses)]
  tma_info_bottleneck_instruction_fetch_bw
       [Total pipeline cost of instruction fetch bandwidth related bottlenecks]
  tma_info_frontend_dsb_coverage
       [Fraction of Uops delivered by the DSB (aka Decoded ICache; or Uop
        Cache)]
  tma_info_frontend_fetch_upc
       [Average number of Uops issued by front-end when it issued something]
  tma_info_frontend_icache_miss_latency
       [Average Latency for L1 instruction cache misses]
  tma_info_frontend_ipdsb_miss_ret
       [Instructions per non-speculative DSB miss (lower number means higher
        occurrence rate)]
  tma_info_frontend_ipunknown_branch
       [Instructions per speculative Unknown Branch Misprediction (BAClear)
        (lower number means higher occurrence rate)]
  tma_info_frontend_lsd_coverage
       [Fraction of Uops delivered by the LSD (Loop Stream Detector; aka Loop
        Cache)]
  tma_info_inst_mix_bptkbranch
       [Branch instructions per taken branch]
  tma_info_inst_mix_ipbranch
       [Instructions per Branch (lower number means higher occurrence rate)]
  tma_info_inst_mix_ipcall
       [Instructions per (near) call (lower number means higher occurrence
        rate)]
  tma_info_inst_mix_iptb
       [Instruction per taken branch]
  tma_info_memory_tlb_code_stlb_mpki
       [STLB (2nd level TLB) code speculative misses per kilo instruction
        (misses of any page-size that complete the page walk)]
  tma_info_thread_uptb
       [Instruction per taken branch]

FetchBW: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_decoder0_alone
       [This metric represents fraction of cycles where decoder-0 was the only
        active decoder]
  tma_dsb
       [This metric represents Core fraction of cycles in which CPU was likely
        limited due to DSB (decoded uop cache) fetch pipeline]
  tma_fetch_bandwidth
       [This metric represents fraction of slots the CPU was stalled due to
        Frontend bandwidth issues]
  tma_info_bottleneck_instruction_fetch_bw
       [Total pipeline cost of instruction fetch bandwidth related bottlenecks]
  tma_info_frontend_dsb_coverage
       [Fraction of Uops delivered by the DSB (aka Decoded ICache; or Uop
        Cache)]
  tma_info_frontend_fetch_upc
       [Average number of Uops issued by front-end when it issued something]
  tma_info_inst_mix_iptb
       [Instruction per taken branch]
  tma_info_thread_uptb
       [Instruction per taken branch]
  tma_lsd
       [This metric represents Core fraction of cycles in which CPU was likely
        limited due to LSD (Loop Stream Detector) unit]
  tma_mite
       [This metric represents Core fraction of cycles in which CPU was likely
        limited due to the MITE pipeline (the legacy decode pipeline)]

FetchLat: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_branch_resteers
       [This metric represents fraction of cycles the CPU was stalled due to
        Branch Resteers]
  tma_dsb_switches
       [This metric represents fraction of cycles the CPU was stalled due to
        switches from DSB to MITE pipelines]
  tma_icache_misses
       [This metric represents fraction of cycles the CPU was stalled due to
        instruction cache misses]
  tma_info_botlnk_l2_ic_misses
       [Total pipeline cost of Instruction Cache misses - subset of the
        Big_Code Bottleneck]
  tma_info_frontend_icache_miss_latency
       [Average Latency for L1 instruction cache misses]
  tma_itlb_misses
       [This metric represents fraction of cycles the CPU was stalled due to
        Instruction TLB (ITLB) misses]
  tma_lcp
       [This metric represents fraction of cycles CPU was stalled due to
        Length Changing Prefixes (LCPs)]
  tma_ms_switches
       [This metric estimates the fraction of cycles when the CPU was stalled
        due to switches of uop delivery to the Microcode Sequencer (MS)]
  tma_unknown_branches
       [This metric represents fraction of cycles the CPU was stalled due to
        new branch address clears]

Flops: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_fp_scalar
       [This metric approximates arithmetic floating-point (FP) scalar uops
        fraction the CPU has retired]
  tma_fp_vector
       [This metric approximates arithmetic floating-point (FP) vector uops
        fraction the CPU has retired aggregated across all vector widths]
  tma_fp_vector_128b
       [This metric approximates arithmetic FP vector uops fraction the CPU
        has retired for 128-bit wide vectors]
  tma_fp_vector_256b
       [This metric approximates arithmetic FP vector uops fraction the CPU
        has retired for 256-bit wide vectors]
  tma_info_core_flopc
       [Floating Point Operations Per Cycle]
  tma_info_core_fp_arith_utilization
       [Actual per-core usage of the Floating Point non-X87 execution units
        (regardless of precision or vector-width)]
  tma_info_inst_mix_iparith
       [Instructions per FP Arithmetic instruction (lower number means higher
        occurrence rate)]
  tma_info_inst_mix_iparith_avx128
       [Instructions per FP Arithmetic AVX/SSE 128-bit instruction (lower
        number means higher occurrence rate)]
  tma_info_inst_mix_iparith_avx256
       [Instructions per FP Arithmetic AVX* 256-bit instruction (lower number
        means higher occurrence rate)]
  tma_info_inst_mix_iparith_scalar_dp
       [Instructions per FP Arithmetic Scalar Double-Precision instruction
        (lower number means higher occurrence rate)]
  tma_info_inst_mix_iparith_scalar_sp
       [Instructions per FP Arithmetic Scalar Single-Precision instruction
        (lower number means higher occurrence rate)]
  tma_info_inst_mix_ipflop
       [Instructions per Floating Point (FP) Operation (lower number means
        higher occurrence rate)]
  tma_info_system_gflops
       [Giga Floating Point Operations Per Second]

FpScalar: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_info_inst_mix_iparith_scalar_dp
       [Instructions per FP Arithmetic Scalar Double-Precision instruction
        (lower number means higher occurrence rate)]
  tma_info_inst_mix_iparith_scalar_sp
       [Instructions per FP Arithmetic Scalar Single-Precision instruction
        (lower number means higher occurrence rate)]

FpVector: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_info_inst_mix_iparith_avx128
       [Instructions per FP Arithmetic AVX/SSE 128-bit instruction (lower
        number means higher occurrence rate)]
  tma_info_inst_mix_iparith_avx256
       [Instructions per FP Arithmetic AVX* 256-bit instruction (lower number
        means higher occurrence rate)]

Frontend: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_fetch_bandwidth
       [This metric represents fraction of slots the CPU was stalled due to
        Frontend bandwidth issues]
  tma_fetch_latency
       [This metric represents fraction of slots the CPU was stalled due to
        Frontend latency issues]
  tma_info_bottleneck_big_code
       [Total pipeline cost of instruction fetch related bottlenecks by large
        code footprint programs (i-side cache; TLB and BTB misses)]
  tma_info_bottleneck_instruction_fetch_bw
       [Total pipeline cost of instruction fetch bandwidth related bottlenecks]
  tma_info_inst_mix_iptb
       [Instruction per taken branch]

HPC: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_avx_assists
       [This metric estimates fraction of slots the CPU retired uops as a
        result of handing SSE to AVX* or AVX* to SSE transition Assists]
  tma_fp_arith
       [This metric represents overall arithmetic floating-point (FP)
        operations fraction the CPU has executed (retired)]
  tma_fp_assists
       [This metric roughly estimates fraction of slots the CPU retired uops
        as a result of handing Floating Point (FP) Assists]
  tma_info_core_fp_arith_utilization
       [Actual per-core usage of the Floating Point non-X87 execution units
        (regardless of precision or vector-width)]
  tma_info_system_cpu_utilization
       [Average CPU Utilization]
  tma_info_system_dram_bw_use
       [Average external Memory Bandwidth Use for reads and writes [GB / sec]]
  tma_info_system_gflops
       [Giga Floating Point Operations Per Second]
  tma_shuffles
       [This metric represents Shuffle (cross "vector lane" data transfers)
        uops fraction the CPU has retired]

IcMiss: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_icache_misses
       [This metric represents fraction of cycles the CPU was stalled due to
        instruction cache misses]
  tma_info_botlnk_l2_ic_misses
       [Total pipeline cost of Instruction Cache misses - subset of the
        Big_Code Bottleneck]
  tma_info_bottleneck_big_code
       [Total pipeline cost of instruction fetch related bottlenecks by large
        code footprint programs (i-side cache; TLB and BTB misses)]
  tma_info_frontend_icache_miss_latency
       [Average Latency for L1 instruction cache misses]
  tma_info_frontend_l2mpki_code
       [L2 cache true code cacheline misses per kilo instruction]
  tma_info_frontend_l2mpki_code_all
       [L2 cache speculative code cacheline misses per kilo instruction]

InsType: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_info_inst_mix_iparith
       [Instructions per FP Arithmetic instruction (lower number means higher
        occurrence rate)]
  tma_info_inst_mix_iparith_avx128
       [Instructions per FP Arithmetic AVX/SSE 128-bit instruction (lower
        number means higher occurrence rate)]
  tma_info_inst_mix_iparith_avx256
       [Instructions per FP Arithmetic AVX* 256-bit instruction (lower number
        means higher occurrence rate)]
  tma_info_inst_mix_iparith_scalar_dp
       [Instructions per FP Arithmetic Scalar Double-Precision instruction
        (lower number means higher occurrence rate)]
  tma_info_inst_mix_iparith_scalar_sp
       [Instructions per FP Arithmetic Scalar Single-Precision instruction
        (lower number means higher occurrence rate)]
  tma_info_inst_mix_ipbranch
       [Instructions per Branch (lower number means higher occurrence rate)]
  tma_info_inst_mix_ipflop
       [Instructions per Floating Point (FP) Operation (lower number means
        higher occurrence rate)]
  tma_info_inst_mix_ipload
       [Instructions per Load (lower number means higher occurrence rate)]
  tma_info_inst_mix_ipstore
       [Instructions per Store (lower number means higher occurrence rate)]

IntVector: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_int_vector_128b
       [This metric represents 128-bit vector Integer ADD/SUB/SAD or VNNI
        (Vector Neural Network Instructions) uops fraction the CPU has retired]
  tma_int_vector_256b
       [This metric represents 256-bit vector Integer ADD/SUB/SAD or VNNI
        (Vector Neural Network Instructions) uops fraction the CPU has retired]

LSD: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_info_frontend_lsd_coverage
       [Fraction of Uops delivered by the LSD (Loop Stream Detector; aka Loop
        Cache)]
  tma_lsd
       [This metric represents Core fraction of cycles in which CPU was likely
        limited due to LSD (Loop Stream Detector) unit]

MachineClears: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_clears_resteers
       [This metric represents fraction of cycles the CPU was stalled due to
        Branch Resteers as a result of Machine Clears]
  tma_machine_clears
       [This metric represents fraction of slots the CPU has wasted due to
        Machine Clears]

Mem: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_info_bottleneck_memory_bandwidth
       [Total pipeline cost of (external) Memory Bandwidth related bottlenecks]
  tma_info_bottleneck_memory_data_tlbs
       [Total pipeline cost of Memory Address Translation related bottlenecks
        (data-side TLBs)]
  tma_info_bottleneck_memory_latency
       [Total pipeline cost of Memory Latency related bottlenecks (external
        memory and off-core caches)]
  tma_info_memory_core_l1d_cache_fill_bw
       [Average per-core data fill bandwidth to the L1 data cache [GB / sec]]
  tma_info_memory_core_l2_cache_fill_bw
       [Average per-core data fill bandwidth to the L2 cache [GB / sec]]
  tma_info_memory_core_l3_cache_access_bw
       [Average per-core data access bandwidth to the L3 cache [GB / sec]]
  tma_info_memory_core_l3_cache_fill_bw
       [Average per-core data fill bandwidth to the L3 cache [GB / sec]]
  tma_info_memory_fb_hpki
       [Fill Buffer (FB) hits per kilo instructions for retired demand loads
        (L1D misses that merge into ongoing miss-handling entries)]
  tma_info_memory_l1mpki
       [L1 cache true misses per kilo instruction for retired demand loads]
  tma_info_memory_l1mpki_load
       [L1 cache true misses per kilo instruction for all demand loads
        (including speculative)]
  tma_info_memory_l2hpki_all
       [L2 cache hits per kilo instruction for all request types (including
        speculative)]
  tma_info_memory_l2hpki_load
       [L2 cache hits per kilo instruction for all demand loads (including
        speculative)]
  tma_info_memory_l2mpki
       [L2 cache true misses per kilo instruction for retired demand loads]
  tma_info_memory_l2mpki_all
       [L2 cache ([RKL+] true) misses per kilo instruction for all request
        types (including speculative)]
  tma_info_memory_l2mpki_load
       [L2 cache ([RKL+] true) misses per kilo instruction for all demand
        loads (including speculative)]
  tma_info_memory_l3mpki
       [L3 cache true misses per kilo instruction for retired demand loads]
  tma_info_memory_load_miss_real_latency
       [Actual Average Latency for L1 data-cache miss demand load operations
        (in core cycles)]
  tma_info_memory_mlp
       [Memory-Level-Parallelism (average number of L1 miss demand load when
        there is at least one such miss]
  tma_info_memory_thread_l1d_cache_fill_bw_1t
       [Average per-thread data fill bandwidth to the L1 data cache [GB / sec]]
  tma_info_memory_thread_l2_cache_fill_bw_1t
       [Average per-thread data fill bandwidth to the L2 cache [GB / sec]]
  tma_info_memory_thread_l3_cache_access_bw_1t
       [Average per-thread data access bandwidth to the L3 cache [GB / sec]]
  tma_info_memory_thread_l3_cache_fill_bw_1t
       [Average per-thread data fill bandwidth to the L3 cache [GB / sec]]
  tma_info_memory_tlb_load_stlb_mpki
       [STLB (2nd level TLB) data load speculative misses per kilo instruction
        (misses of any page-size that complete the page walk)]
  tma_info_memory_tlb_page_walks_utilization
       [Utilization of the core's Page Walker(s) serving STLB misses triggered
        by instruction/Load/Store accesses]
  tma_info_memory_tlb_store_stlb_mpki
       [STLB (2nd level TLB) data store speculative misses per kilo
        instruction (misses of any page-size that complete the page walk)]
  tma_info_system_dram_bw_use
       [Average external Memory Bandwidth Use for reads and writes [GB / sec]]
  tma_info_system_mem_parallel_reads
       [Average number of parallel data read requests to external memory]
  tma_info_system_mem_read_latency
       [Average latency of data read request to external memory (in
        nanoseconds)]
  tma_info_system_mem_request_latency
       [Average latency of all requests to external memory (in Uncore cycles)]
  tma_info_thread_cpi
       [Cycles Per Instruction (per Logical Processor)]

MemoryBW: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_fb_full
       [This metric does a *rough estimation* of how often L1D Fill Buffer
        unavailability limited additional L1D miss memory access requests to
        proceed]
  tma_info_bottleneck_memory_bandwidth
       [Total pipeline cost of (external) Memory Bandwidth related bottlenecks]
  tma_info_memory_core_l1d_cache_fill_bw
       [Average per-core data fill bandwidth to the L1 data cache [GB / sec]]
  tma_info_memory_core_l2_cache_fill_bw
       [Average per-core data fill bandwidth to the L2 cache [GB / sec]]
  tma_info_memory_core_l3_cache_access_bw
       [Average per-core data access bandwidth to the L3 cache [GB / sec]]
  tma_info_memory_core_l3_cache_fill_bw
       [Average per-core data fill bandwidth to the L3 cache [GB / sec]]
  tma_info_memory_mlp
       [Memory-Level-Parallelism (average number of L1 miss demand load when
        there is at least one such miss]
  tma_info_memory_thread_l1d_cache_fill_bw_1t
       [Average per-thread data fill bandwidth to the L1 data cache [GB / sec]]
  tma_info_memory_thread_l2_cache_fill_bw_1t
       [Average per-thread data fill bandwidth to the L2 cache [GB / sec]]
  tma_info_memory_thread_l3_cache_access_bw_1t
       [Average per-thread data access bandwidth to the L3 cache [GB / sec]]
  tma_info_memory_thread_l3_cache_fill_bw_1t
       [Average per-thread data fill bandwidth to the L3 cache [GB / sec]]
  tma_info_system_dram_bw_use
       [Average external Memory Bandwidth Use for reads and writes [GB / sec]]
  tma_info_system_mem_parallel_reads
       [Average number of parallel data read requests to external memory]
  tma_mem_bandwidth
       [This metric estimates fraction of cycles where the core's performance
        was likely hurt due to approaching bandwidth limits of external memory
        (DRAM)]
  tma_sq_full
       [This metric measures fraction of cycles where the Super Queue (SQ) was
        full taking into account all request-types and both hardware SMT
        threads (Logical Processors)]
  tma_streaming_stores
       [This metric estimates how often CPU was stalled due to Streaming store
        memory accesses; Streaming store optimize out a read request required
        by RFO stores]

MemoryBound: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_dram_bound
       [This metric estimates how often the CPU was stalled on accesses to
        external memory (DRAM) by loads]
  tma_info_memory_load_miss_real_latency
       [Actual Average Latency for L1 data-cache miss demand load operations
        (in core cycles)]
  tma_info_memory_mlp
       [Memory-Level-Parallelism (average number of L1 miss demand load when
        there is at least one such miss]
  tma_l1_bound
       [This metric estimates how often the CPU was stalled without loads
        missing the L1 data cache]
  tma_l2_bound
       [This metric estimates how often the CPU was stalled due to L2 cache
        accesses by loads]
  tma_l3_bound
       [This metric estimates how often the CPU was stalled due to loads
        accesses to L3 cache or contended with a sibling Core]
  tma_store_bound
       [This metric estimates how often CPU was stalled due to RFO store
        memory accesses; RFO store issue a read-for-ownership request before
        the write]

MemoryLat: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_info_bottleneck_memory_latency
       [Total pipeline cost of Memory Latency related bottlenecks (external
        memory and off-core caches)]
  tma_info_memory_load_miss_real_latency
       [Actual Average Latency for L1 data-cache miss demand load operations
        (in core cycles)]
  tma_info_system_mem_read_latency
       [Average latency of data read request to external memory (in
        nanoseconds)]
  tma_l3_hit_latency
       [This metric represents fraction of cycles with demand load accesses
        that hit the L3 cache under unloaded scenarios (possibly L3 latency
        limited)]
  tma_mem_latency
       [This metric estimates fraction of cycles where the performance was
        likely hurt due to latency from external memory (DRAM)]
  tma_store_latency
       [This metric estimates fraction of cycles the CPU spent handling L1D
        store misses]

MemoryTLB: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_dtlb_load
       [This metric roughly estimates the fraction of cycles where the Data
        TLB (DTLB) was missed by load accesses]
  tma_dtlb_store
       [This metric roughly estimates the fraction of cycles spent handling
        first-level data TLB store misses]
  tma_info_bottleneck_big_code
       [Total pipeline cost of instruction fetch related bottlenecks by large
        code footprint programs (i-side cache; TLB and BTB misses)]
  tma_info_bottleneck_memory_data_tlbs
       [Total pipeline cost of Memory Address Translation related bottlenecks
        (data-side TLBs)]
  tma_info_memory_tlb_code_stlb_mpki
       [STLB (2nd level TLB) code speculative misses per kilo instruction
        (misses of any page-size that complete the page walk)]
  tma_info_memory_tlb_load_stlb_mpki
       [STLB (2nd level TLB) data load speculative misses per kilo instruction
        (misses of any page-size that complete the page walk)]
  tma_info_memory_tlb_page_walks_utilization
       [Utilization of the core's Page Walker(s) serving STLB misses triggered
        by instruction/Load/Store accesses]
  tma_info_memory_tlb_store_stlb_mpki
       [STLB (2nd level TLB) data store speculative misses per kilo
        instruction (misses of any page-size that complete the page walk)]
  tma_itlb_misses
       [This metric represents fraction of cycles the CPU was stalled due to
        Instruction TLB (ITLB) misses]
  tma_load_stlb_hit
       [This metric roughly estimates the fraction of cycles where the (first
        level) DTLB was missed by load accesses, that later on hit in
        second-level TLB (STLB)]
  tma_load_stlb_miss
       [This metric estimates the fraction of cycles where the Second-level
        TLB (STLB) was missed by load accesses, performing a hardware page
        walk]
  tma_store_stlb_hit
       [This metric roughly estimates the fraction of cycles where the TLB was
        missed by store accesses, hitting in the second-level TLB (STLB)]
  tma_store_stlb_miss
       [This metric estimates the fraction of cycles where the STLB was missed
        by store accesses, performing a hardware page walk]

Memory_BW: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_info_memory_oro_data_l2_mlp
       [Average Parallel L2 cache miss data reads]
  tma_info_memory_oro_load_l2_mlp
       [Average Parallel L2 cache miss demand Loads]

Memory_Lat: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_info_memory_oro_load_l2_miss_latency
       [Average Latency for L2 cache miss demand Loads]
  tma_info_memory_oro_load_l3_miss_latency
       [Average Latency for L3 cache miss demand Loads]

MicroSeq: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_microcode_sequencer
       [This metric represents fraction of slots the CPU was retiring uops
        fetched by the Microcode Sequencer (MS) unit]
  tma_ms_switches
       [This metric estimates the fraction of cycles when the CPU was stalled
        due to switches of uop delivery to the Microcode Sequencer (MS)]

No_group:
  tma_info_core_clks
  tma_info_core_clks_p
  tma_info_core_cpi
       [Cycles Per Instruction]
  tma_info_core_ipc
       [Instructions Per Cycle]
  tma_info_core_slots
  tma_info_core_upi
       [Uops Per Instruction]
  tma_info_frontend_inst_miss_cost_dramhit_percent
       [Percent of instruction miss cost that hit in DRAM]
  tma_info_frontend_inst_miss_cost_l2hit_percent
       [Percent of instruction miss cost that hit in the L2]
  tma_info_frontend_inst_miss_cost_l3hit_percent
       [Percent of instruction miss cost that hit in the L3]
  tma_info_inst_mix_branch_mispredict_ratio
       [Ratio of all branches which mispredict]
  tma_info_inst_mix_branch_mispredict_to_unknown_branch_ratio
       [Ratio between Mispredicted branches and unknown branches]
  tma_info_inst_mix_fpdiv_uop_ratio
       [Percentage of all uops which are FPDiv uops]
  tma_info_inst_mix_idiv_uop_ratio
       [Percentage of all uops which are IDiv uops]
  tma_info_inst_mix_ipbranch
       [Instructions per Branch (lower number means higher occurrence rate)]
  tma_info_inst_mix_ipcall
       [Instruction per (near) call (lower number means higher occurrence
        rate)]
  tma_info_inst_mix_ipfarbranch
       [Instructions per Far Branch]
  tma_info_inst_mix_ipload
       [Instructions per Load]
  tma_info_inst_mix_ipmisp_cond_ntaken
       [Instructions per retired conditional Branch Misprediction where the
        branch was not taken]
  tma_info_inst_mix_ipmisp_cond_taken
       [Instructions per retired conditional Branch Misprediction where the
        branch was taken]
  tma_info_inst_mix_ipmisp_indirect
       [Instructions per retired indirect call or jump Branch Misprediction]
  tma_info_inst_mix_ipmisp_ret
       [Instructions per retired return Branch Misprediction]
  tma_info_inst_mix_ipmispredict
       [Instructions per retired Branch Misprediction]
  tma_info_inst_mix_ipstore
       [Instructions per Store]
  tma_info_inst_mix_microcode_uop_ratio
       [Percentage of all uops which are ucode ops]
  tma_info_inst_mix_x87_uop_ratio
       [Percentage of all uops which are x87 uops]
  tma_info_l1_bound_address_alias_blocks
       [Percentage of total non-speculative loads with a address aliasing
        block]
  tma_info_l1_bound_load_splits
       [Percentage of total non-speculative loads that are splits]
  tma_info_l1_bound_store_fwd_blocks
       [Percentage of total non-speculative loads with a store forward or
        unknown store address block]
  tma_info_memory_cycles_per_demand_load_dram_hit
       [Cycle cost per DRAM hit]
  tma_info_memory_cycles_per_demand_load_l2_hit
       [Cycle cost per L2 hit]
  tma_info_memory_cycles_per_demand_load_l3_hit
       [Cycle cost per LLC hit]
  tma_info_memory_memloadpki
       [load ops retired per 1000 instruction]
  tma_info_system_cpu_utilization
       [Average CPU Utilization]

OS: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_info_system_ipfarbranch
       [Instructions per Far Branch ( Far Branches apply upon transition from
        application to operating system, handling interrupts, exceptions)
        [lower number means higher occurrence rate]]
  tma_info_system_kernel_cpi
       [Cycles Per Instruction for the Operating System (OS) Kernel mode]
  tma_info_system_kernel_utilization
       [Fraction of cycles spent in the Operating System (OS) Kernel mode]

Offcore: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_contested_accesses
       [This metric estimates fraction of cycles while the memory subsystem
        was handling synchronizations due to contested accesses]
  tma_data_sharing
       [This metric estimates fraction of cycles while the memory subsystem
        was handling synchronizations due to data-sharing accesses]
  tma_false_sharing
       [This metric roughly estimates how often CPU was handling
        synchronizations due to False Sharing]
  tma_info_bottleneck_memory_bandwidth
       [Total pipeline cost of (external) Memory Bandwidth related bottlenecks]
  tma_info_bottleneck_memory_data_tlbs
       [Total pipeline cost of Memory Address Translation related bottlenecks
        (data-side TLBs)]
  tma_info_bottleneck_memory_latency
       [Total pipeline cost of Memory Latency related bottlenecks (external
        memory and off-core caches)]
  tma_info_memory_core_l3_cache_access_bw
       [Average per-core data access bandwidth to the L3 cache [GB / sec]]
  tma_info_memory_l2mpki_all
       [L2 cache ([RKL+] true) misses per kilo instruction for all request
        types (including speculative)]
  tma_info_memory_oro_data_l2_mlp
       [Average Parallel L2 cache miss data reads]
  tma_info_memory_oro_load_l2_miss_latency
       [Average Latency for L2 cache miss demand Loads]
  tma_info_memory_oro_load_l2_mlp
       [Average Parallel L2 cache miss demand Loads]
  tma_info_memory_oro_load_l3_miss_latency
       [Average Latency for L3 cache miss demand Loads]
  tma_info_memory_thread_l3_cache_access_bw_1t
       [Average per-thread data access bandwidth to the L3 cache [GB / sec]]
  tma_lock_latency
       [This metric represents fraction of cycles the CPU spent handling cache
        misses due to lock operations]
  tma_mem_bandwidth
       [This metric estimates fraction of cycles where the core's performance
        was likely hurt due to approaching bandwidth limits of external memory
        (DRAM)]
  tma_mem_latency
       [This metric estimates fraction of cycles where the performance was
        likely hurt due to latency from external memory (DRAM)]
  tma_sq_full
       [This metric measures fraction of cycles where the Super Queue (SQ) was
        full taking into account all request-types and both hardware SMT
        threads (Logical Processors)]
  tma_store_latency
       [This metric estimates fraction of cycles the CPU spent handling L1D
        store misses]
  tma_streaming_stores
       [This metric estimates how often CPU was stalled due to Streaming store
        memory accesses; Streaming store optimize out a read request required
        by RFO stores]

PGO: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_frontend_bound
       [This category represents fraction of slots where the processor's
        Frontend undersupplies its Backend]
  tma_info_branches_cond_nt
       [Fraction of branches that are non-taken conditionals]
  tma_info_branches_cond_tk
       [Fraction of branches that are taken conditionals]
  tma_info_inst_mix_bptkbranch
       [Branch instructions per taken branch]
  tma_info_inst_mix_ipcall
       [Instructions per (near) call (lower number means higher occurrence
        rate)]
  tma_info_inst_mix_iptb
       [Instruction per taken branch]

Pipeline: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_fused_instructions
       [This metric represents fraction of slots where the CPU was retiring
        fused instructions -- where one uop can represent multiple contiguous
        instructions]
  tma_info_core_ilp
       [Instruction-Level-Parallelism (average number of uops executed when
        there is execution) per-core]
  tma_info_pipeline_execute
       [Instruction-Level-Parallelism (average number of uops executed when
        there is execution) per-thread]
  tma_info_pipeline_ipassist
       [Instructions per a microcode Assist invocation]
  tma_info_pipeline_retire
       [Average number of Uops retired in cycles where at least one uop has
        retired]
  tma_info_pipeline_strings_cycles
       [Estimated fraction of retirement-cycles dealing with repeat
        instructions]
  tma_info_thread_clks
       [Per-Logical Processor actual clocks when the Logical Processor is
        active]
  tma_info_thread_cpi
       [Cycles Per Instruction (per Logical Processor)]
  tma_info_thread_execute_per_issue
       [The ratio of Executed- by Issued-Uops]
  tma_info_thread_uoppi
       [Uops Per Instruction]
  tma_int_operations
       [This metric represents overall Integer (Int) select operations
        fraction the CPU has executed (retired)]
  tma_int_vector_128b
       [This metric represents 128-bit vector Integer ADD/SUB/SAD or VNNI
        (Vector Neural Network Instructions) uops fraction the CPU has retired]
  tma_int_vector_256b
       [This metric represents 256-bit vector Integer ADD/SUB/SAD or VNNI
        (Vector Neural Network Instructions) uops fraction the CPU has retired]
  tma_memory_operations
       [This metric represents fraction of slots where the CPU was retiring
        memory operations -- uops for memory load or store accesses]
  tma_non_fused_branches
       [This metric represents fraction of slots where the CPU was retiring
        branch instructions that were not fused]
  tma_nop_instructions
       [This metric represents fraction of slots where the CPU was retiring
        NOP (no op) instructions]
  tma_other_light_ops
       [This metric represents the remaining light uops fraction the CPU has
        executed - remaining means not covered by other sibling nodes]
  tma_shuffles
       [This metric represents Shuffle (cross "vector lane" data transfers)
        uops fraction the CPU has retired]

PortsUtil: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_info_core_ilp
       [Instruction-Level-Parallelism (average number of uops executed when
        there is execution) per-core]
  tma_info_pipeline_execute
       [Instruction-Level-Parallelism (average number of uops executed when
        there is execution) per-thread]
  tma_ports_utilization
       [This metric estimates fraction of cycles the CPU performance was
        potentially limited due to Core computation issues (non
        divider-related)]
  tma_ports_utilized_0
       [This metric represents fraction of cycles CPU executed no uops on any
        execution port (Logical Processor cycles since ICL, Physical Core
        cycles otherwise)]
  tma_ports_utilized_1
       [This metric represents fraction of cycles where the CPU executed total
        of 1 uop per cycle on all execution ports (Logical Processor cycles
        since ICL, Physical Core cycles otherwise)]
  tma_ports_utilized_2
       [This metric represents fraction of cycles CPU executed total of 2 uops
        per cycle on all execution ports (Logical Processor cycles since ICL,
        Physical Core cycles otherwise)]
  tma_ports_utilized_3m
       [This metric represents fraction of cycles CPU executed total of 3 or
        more uops per cycle on all execution ports (Logical Processor cycles
        since ICL, Physical Core cycles otherwise)]
  tma_serializing_operation
       [This metric represents fraction of cycles the CPU issue-pipeline was
        stalled due to serializing operations]

Power: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  C10_Pkg_Residency
       [C10 residency percent per package]
  C1_Core_Residency
       [C1 residency percent per core]
  C2_Pkg_Residency
       [C2 residency percent per package]
  C3_Pkg_Residency
       [C3 residency percent per package]
  C6_Core_Residency
       [C6 residency percent per core]
  C6_Pkg_Residency
       [C6 residency percent per package]
  C7_Core_Residency
       [C7 residency percent per core]
  C7_Pkg_Residency
       [C7 residency percent per package]
  C8_Pkg_Residency
       [C8 residency percent per package]
  C9_Pkg_Residency
       [C9 residency percent per package]
  tma_info_system_average_frequency
       [Measured Average Frequency for unhalted processors [GHz]]
  tma_info_system_turbo_utilization
       [Average Frequency Utilization relative nominal frequency]

Prefetches: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_info_inst_mix_ipswpf
       [Instructions per Software prefetch instruction (of any type:
        NTA/T0/T1/T2/Prefetch) (lower number means higher occurrence rate)]

Ret: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_info_bottleneck_branching_overhead
       [Total pipeline cost of branch related instructions (used for program
        control-flow including function calls)]
  tma_info_core_coreipc
       [Instructions Per Cycle across hyper-threads (per physical core)]
  tma_info_core_flopc
       [Floating Point Operations Per Cycle]
  tma_info_pipeline_ipassist
       [Instructions per a microcode Assist invocation]
  tma_info_pipeline_retire
       [Average number of Uops retired in cycles where at least one uop has
        retired]
  tma_info_pipeline_strings_cycles
       [Estimated fraction of retirement-cycles dealing with repeat
        instructions]
  tma_info_thread_ipc
       [Instructions Per Cycle (per Logical Processor)]
  tma_info_thread_uoppi
       [Uops Per Instruction]

Retire: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_heavy_operations
       [This metric represents fraction of slots where the CPU was retiring
        heavy-weight operations -- instructions that require two or more uops
        or micro-coded sequences]
  tma_info_pipeline_ipassist
       [Instructions per a microcode Assist invocation]
  tma_info_thread_uoppi
       [Uops Per Instruction]
  tma_light_operations
       [This metric represents fraction of slots where the CPU was retiring
        light-weight operations -- instructions that require no more than one
        uop (micro-operation)]

SMT: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_info_botlnk_l0_core_bound_likely
       [Probability of Core Bound bottleneck hidden by SMT-profiling artifacts]
  tma_info_core_core_clks
       [Core actual clocks when any Logical Processor is active on the
        Physical Core]
  tma_info_core_coreipc
       [Instructions Per Cycle across hyper-threads (per physical core)]
  tma_info_pipeline_execute
       [Instruction-Level-Parallelism (average number of uops executed when
        there is execution) per-thread]
  tma_info_system_smt_2t_utilization
       [Fraction of cycles where both hardware Logical Processors were active]
  tma_info_thread_slots_utilization
       [Fraction of Physical Core issue-slots utilized by this Logical
        Processor]

Snoop: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_contested_accesses
       [This metric estimates fraction of cycles while the memory subsystem
        was handling synchronizations due to contested accesses]
  tma_data_sharing
       [This metric estimates fraction of cycles while the memory subsystem
        was handling synchronizations due to data-sharing accesses]
  tma_false_sharing
       [This metric roughly estimates how often CPU was handling
        synchronizations due to False Sharing]

SoC: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  UNCORE_FREQ
       [Uncore frequency per die [GHZ]]
  tma_info_system_dram_bw_use
       [Average external Memory Bandwidth Use for reads and writes [GB / sec]]
  tma_info_system_mem_parallel_reads
       [Average number of parallel data read requests to external memory]
  tma_info_system_mem_read_latency
       [Average latency of data read request to external memory (in
        nanoseconds)]
  tma_info_system_mem_request_latency
       [Average latency of all requests to external memory (in Uncore cycles)]
  tma_info_system_socket_clks
       [Socket actual clocks when any core is active on that socket]

Summary: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_info_inst_mix_instructions
       [Total number of retired Instructions]
  tma_info_system_average_frequency
       [Measured Average Frequency for unhalted processors [GHz]]
  tma_info_system_cpu_utilization
       [Average CPU Utilization]
  tma_info_system_kernel_utilization
       [Fraction of cycles spent in Kernel mode]
  tma_info_thread_ipc
       [Instructions Per Cycle (per Logical Processor)]

TmaL1: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_backend_bound
       [This category represents fraction of slots where no uops are being
        delivered due to a lack of required resources for accepting new uops
        in the Backend]
  tma_bad_speculation
       [This category represents fraction of slots wasted due to incorrect
        speculations]
  tma_frontend_bound
       [This category represents fraction of slots where the processor's
        Frontend undersupplies its Backend]
  tma_info_core_coreipc
       [Instructions Per Cycle across hyper-threads (per physical core)]
  tma_info_inst_mix_instructions
       [Total number of retired Instructions]
  tma_info_thread_slots
       [Total issue-pipeline slots (per-Physical Core till ICL; per-Logical
        Processor ICL onward)]
  tma_info_thread_slots_utilization
       [Fraction of Physical Core issue-slots utilized by this Logical
        Processor]
  tma_retiring
       [This category represents fraction of slots utilized by useful work
        i.e. issued uops that eventually get retired]

TmaL2: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_branch_mispredicts
       [This metric represents fraction of slots the CPU has wasted due to
        Branch Misprediction]
  tma_core_bound
       [This metric represents fraction of slots where Core non-memory issues
        were of a bottleneck]
  tma_fetch_bandwidth
       [This metric represents fraction of slots the CPU was stalled due to
        Frontend bandwidth issues]
  tma_fetch_latency
       [This metric represents fraction of slots the CPU was stalled due to
        Frontend latency issues]
  tma_heavy_operations
       [This metric represents fraction of slots where the CPU was retiring
        heavy-weight operations -- instructions that require two or more uops
        or micro-coded sequences]
  tma_light_operations
       [This metric represents fraction of slots where the CPU was retiring
        light-weight operations -- instructions that require no more than one
        uop (micro-operation)]
  tma_machine_clears
       [This metric represents fraction of slots the CPU has wasted due to
        Machine Clears]
  tma_memory_bound
       [This metric represents fraction of slots the Memory subsystem within
        the Backend was a bottleneck]

TmaL3mem: [Grouping from Top-down Microarchitecture Analysis Metrics spreadsheet]
  tma_dram_bound
       [This metric estimates how often the CPU was stalled on accesses to
        external memory (DRAM) by loads]
  tma_l1_bound
       [This metric estimates how often the CPU was stalled without loads
        missing the L1 data cache]
  tma_l2_bound
       [This metric estimates how often the CPU was stalled due to L2 cache
        accesses by loads]
  tma_l3_bound
       [This metric estimates how often the CPU was stalled due to loads
        accesses to L3 cache or contended with a sibling Core]
  tma_store_bound
       [This metric estimates how often CPU was stalled due to RFO store
        memory accesses; RFO store issue a read-for-ownership request before
        the write]

TopdownL1: [Metrics for top-down breakdown at level 1]
  tma_backend_bound
       [This category represents fraction of slots where no uops are being
        delivered due to a lack of required resources for accepting new uops
        in the Backend]
  tma_backend_bound_aux
       [Counts the total number of issue slots that were not consumed by the
        backend due to backend stalls]
  tma_bad_speculation
       [This category represents fraction of slots wasted due to incorrect
        speculations]
  tma_frontend_bound
       [This category represents fraction of slots where the processor's
        Frontend undersupplies its Backend]
  tma_retiring
       [This category represents fraction of slots utilized by useful work
        i.e. issued uops that eventually get retired]

TopdownL2: [Metrics for top-down breakdown at level 2]
  tma_base
       [Counts the number of uops that are not from the microsequencer]
  tma_branch_mispredicts
       [This metric represents fraction of slots the CPU has wasted due to
        Branch Misprediction]
  tma_core_bound
       [This metric represents fraction of slots where Core non-memory issues
        were of a bottleneck]
  tma_fetch_bandwidth
       [This metric represents fraction of slots the CPU was stalled due to
        Frontend bandwidth issues]
  tma_fetch_latency
       [This metric represents fraction of slots the CPU was stalled due to
        Frontend latency issues]
  tma_heavy_operations
       [This metric represents fraction of slots where the CPU was retiring
        heavy-weight operations -- instructions that require two or more uops
        or micro-coded sequences]
  tma_light_operations
       [This metric represents fraction of slots where the CPU was retiring
        light-weight operations -- instructions that require no more than one
        uop (micro-operation)]
  tma_machine_clears
       [This metric represents fraction of slots the CPU has wasted due to
        Machine Clears]
  tma_memory_bound
       [This metric represents fraction of slots the Memory subsystem within
        the Backend was a bottleneck]
  tma_ms_uops
       [Counts the number of uops that are from the complex flows issued by
        the micro-sequencer (MS)]
  tma_resource_bound
       [Counts the total number of issue slots that were not consumed by the
        backend due to backend stalls]

TopdownL3: [Metrics for top-down breakdown at level 3]
  tma_alloc_restriction
       [Counts the number of issue slots that were not consumed by the backend
        due to certain allocation restrictions]
  tma_branch_detect
       [Counts the number of issue slots that were not delivered by the
        frontend due to BACLEARS, which occurs when the Branch Target Buffer
        (BTB) prediction or lack thereof, was corrected by a later branch
        predictor in the frontend]
  tma_branch_resteer
       [Counts the number of issue slots that were not delivered by the
        frontend due to BTCLEARS, which occurs when the Branch Target Buffer
        (BTB) predicts a taken branch]
  tma_branch_resteers
       [This metric represents fraction of cycles the CPU was stalled due to
        Branch Resteers]
  tma_cisc
       [Counts the number of issue slots that were not delivered by the
        frontend due to the microcode sequencer (MS)]
  tma_decode
       [Counts the number of issue slots that were not delivered by the
        frontend due to decode stalls]
  tma_divider
       [This metric represents fraction of cycles where the Divider unit was
        active]
  tma_dram_bound
       [This metric estimates how often the CPU was stalled on accesses to
        external memory (DRAM) by loads]
  tma_dsb
       [This metric represents Core fraction of cycles in which CPU was likely
        limited due to DSB (decoded uop cache) fetch pipeline]
  tma_dsb_switches
       [This metric represents fraction of cycles the CPU was stalled due to
        switches from DSB to MITE pipelines]
  tma_fast_nuke
       [Counts the number of issue slots that were not consumed by the backend
        due to a machine clear classified as a fast nuke due to memory
        ordering, memory disambiguation and memory renaming]
  tma_few_uops_instructions
       [This metric represents fraction of slots where the CPU was retiring
        instructions that that are decoder into two or up to ([SNB+] four;
        [ADL+] five) uops]
  tma_fp_arith
       [This metric represents overall arithmetic floating-point (FP)
        operations fraction the CPU has executed (retired)]
  tma_fpdiv_uops
       [Counts the number of floating point divide operations per uop]
  tma_fused_instructions
       [This metric represents fraction of slots where the CPU was retiring
        fused instructions -- where one uop can represent multiple contiguous
        instructions]
  tma_icache_misses
       [This metric represents fraction of cycles the CPU was stalled due to
        instruction cache misses]
  tma_int_operations
       [This metric represents overall Integer (Int) select operations
        fraction the CPU has executed (retired)]
  tma_itlb_misses
       [This metric represents fraction of cycles the CPU was stalled due to
        Instruction TLB (ITLB) misses]
  tma_l1_bound
       [This metric estimates how often the CPU was stalled without loads
        missing the L1 data cache]
  tma_l2_bound
       [This metric estimates how often the CPU was stalled due to L2 cache
        accesses by loads]
  tma_l3_bound
       [This metric estimates how often the CPU was stalled due to loads
        accesses to L3 cache or contended with a sibling Core]
  tma_lcp
       [This metric represents fraction of cycles CPU was stalled due to
        Length Changing Prefixes (LCPs)]
  tma_lsd
       [This metric represents Core fraction of cycles in which CPU was likely
        limited due to LSD (Loop Stream Detector) unit]
  tma_mem_scheduler
       [Counts the number of issue slots that were not consumed by the backend
        due to memory reservation stalls in which a scheduler is not able to
        accept uops]
  tma_memory_operations
       [This metric represents fraction of slots where the CPU was retiring
        memory operations -- uops for memory load or store accesses]
  tma_microcode_sequencer
       [This metric represents fraction of slots the CPU was retiring uops
        fetched by the Microcode Sequencer (MS) unit]
  tma_mite
       [This metric represents Core fraction of cycles in which CPU was likely
        limited due to the MITE pipeline (the legacy decode pipeline)]
  tma_ms_switches
       [This metric estimates the fraction of cycles when the CPU was stalled
        due to switches of uop delivery to the Microcode Sequencer (MS)]
  tma_non_fused_branches
       [This metric represents fraction of slots where the CPU was retiring
        branch instructions that were not fused]
  tma_non_mem_scheduler
       [Counts the number of issue slots that were not consumed by the backend
        due to IEC or FPC RAT stalls, which can be due to FIQ or IEC
        reservation stalls in which the integer, floating point or SIMD
        scheduler is not able to accept uops]
  tma_nop_instructions
       [This metric represents fraction of slots where the CPU was retiring
        NOP (no op) instructions]
  tma_nuke
       [Counts the number of issue slots that were not consumed by the backend
        due to a machine clear (slow nuke)]
  tma_other_fb
       [Counts the number of issue slots that were not delivered by the
        frontend due to other common frontend stalls not categorized]
  tma_other_light_ops
       [This metric represents the remaining light uops fraction the CPU has
        executed - remaining means not covered by other sibling nodes]
  tma_other_load_store
       [Counts the number of cycles the core is stalled due to a demand load
        miss which hits in the L2, LLC, DRAM or MMIO (Non-DRAM) but could not
        be correctly attributed or cycles in which the load miss is waiting on
        a request buffer]
  tma_other_ret
       [Counts the number of uops retired excluding ms and fp div uops]
  tma_ports_utilization
       [This metric estimates fraction of cycles the CPU performance was
        potentially limited due to Core computation issues (non
        divider-related)]
  tma_predecode
       [Counts the number of issue slots that were not delivered by the
        frontend due to wrong predecodes]
  tma_register
       [Counts the number of issue slots that were not consumed by the backend
        due to the physical register file unable to accept an entry (marble
        stalls)]
  tma_reorder_buffer
       [Counts the number of issue slots that were not consumed by the backend
        due to the reorder buffer being full (ROB stalls)]
  tma_serialization
       [Counts the number of issue slots that were not consumed by the backend
        due to scoreboards from the instruction queue (IQ), jump execution
        unit (JEU), or microcode sequencer (MS)]
  tma_store_bound
       [This metric estimates how often CPU was stalled due to RFO store
        memory accesses; RFO store issue a read-for-ownership request before
        the write]

TopdownL4: [Metrics for top-down breakdown at level 4]
  tma_assists
       [This metric estimates fraction of slots the CPU retired uops delivered
        by the Microcode_Sequencer as a result of Assists]
  tma_cisc
       [This metric estimates fraction of cycles the CPU retired uops
        originated from CISC (complex instruction set computer) instruction]
  tma_clears_resteers
       [This metric represents fraction of cycles the CPU was stalled due to
        Branch Resteers as a result of Machine Clears]
  tma_contested_accesses
       [This metric estimates fraction of cycles while the memory subsystem
        was handling synchronizations due to contested accesses]
  tma_data_sharing
       [This metric estimates fraction of cycles while the memory subsystem
        was handling synchronizations due to data-sharing accesses]
  tma_decoder0_alone
       [This metric represents fraction of cycles where decoder-0 was the only
        active decoder]
  tma_disambiguation
       [Counts the number of machine clears relative to the number of nuke
        slots due to memory disambiguation]
  tma_dtlb_load
       [This metric roughly estimates the fraction of cycles where the Data
        TLB (DTLB) was missed by load accesses]
  tma_dtlb_store
       [This metric roughly estimates the fraction of cycles spent handling
        first-level data TLB store misses]
  tma_false_sharing
       [This metric roughly estimates how often CPU was handling
        synchronizations due to False Sharing]
  tma_fb_full
       [This metric does a *rough estimation* of how often L1D Fill Buffer
        unavailability limited additional L1D miss memory access requests to
        proceed]
  tma_fp_assist
       [Counts the number of machine clears relative to the number of nuke
        slots due to FP assists]
  tma_fp_scalar
       [This metric approximates arithmetic floating-point (FP) scalar uops
        fraction the CPU has retired]
  tma_fp_vector
       [This metric approximates arithmetic floating-point (FP) vector uops
        fraction the CPU has retired aggregated across all vector widths]
  tma_int_vector_128b
       [This metric represents 128-bit vector Integer ADD/SUB/SAD or VNNI
        (Vector Neural Network Instructions) uops fraction the CPU has retired]
  tma_int_vector_256b
       [This metric represents 256-bit vector Integer ADD/SUB/SAD or VNNI
        (Vector Neural Network Instructions) uops fraction the CPU has retired]
  tma_l3_hit_latency
       [This metric represents fraction of cycles with demand load accesses
        that hit the L3 cache under unloaded scenarios (possibly L3 latency
        limited)]
  tma_ld_buffer
       [Counts the number of cycles, relative to the number of mem_scheduler
        slots, in which uops are blocked due to load buffer full]
  tma_lock_latency
       [This metric represents fraction of cycles the CPU spent handling cache
        misses due to lock operations]
  tma_mem_bandwidth
       [This metric estimates fraction of cycles where the core's performance
        was likely hurt due to approaching bandwidth limits of external memory
        (DRAM)]
  tma_mem_latency
       [This metric estimates fraction of cycles where the performance was
        likely hurt due to latency from external memory (DRAM)]
  tma_memory_ordering
       [Counts the number of machine clears relative to the number of nuke
        slots due to memory ordering]
  tma_mispredicts_resteers
       [This metric represents fraction of cycles the CPU was stalled due to
        Branch Resteers as a result of Branch Misprediction at execution stage]
  tma_other_l1
       [Counts the number of cycles that the oldest load of the load buffer is
        stalled at retirement due to a number of other load blocks]
  tma_page_fault
       [Counts the number of machine clears relative to the number of nuke
        slots due to page faults]
  tma_ports_utilized_0
       [This metric represents fraction of cycles CPU executed no uops on any
        execution port (Logical Processor cycles since ICL, Physical Core
        cycles otherwise)]
  tma_ports_utilized_1
       [This metric represents fraction of cycles where the CPU executed total
        of 1 uop per cycle on all execution ports (Logical Processor cycles
        since ICL, Physical Core cycles otherwise)]
  tma_ports_utilized_2
       [This metric represents fraction of cycles CPU executed total of 2 uops
        per cycle on all execution ports (Logical Processor cycles since ICL,
        Physical Core cycles otherwise)]
  tma_ports_utilized_3m
       [This metric represents fraction of cycles CPU executed total of 3 or
        more uops per cycle on all execution ports (Logical Processor cycles
        since ICL, Physical Core cycles otherwise)]
  tma_rsv
       [Counts the number of cycles, relative to the number of mem_scheduler
        slots, in which uops are blocked due to RSV full relative]
  tma_shuffles
       [This metric represents Shuffle (cross "vector lane" data transfers)
        uops fraction the CPU has retired]
  tma_smc
       [Counts the number of machine clears relative to the number of nuke
        slots due to SMC]
  tma_split_loads
       [This metric estimates fraction of cycles handling memory load split
        accesses - load that cross 64-byte cache line boundary]
  tma_split_stores
       [This metric represents rate of split store accesses]
  tma_sq_full
       [This metric measures fraction of cycles where the Super Queue (SQ) was
        full taking into account all request-types and both hardware SMT
        threads (Logical Processors)]
  tma_st_buffer
       [Counts the number of cycles, relative to the number of mem_scheduler
        slots, in which uops are blocked due to store buffer full]
  tma_stlb_hit
       [Counts the number of cycles that the oldest load of the load buffer is
        stalled at retirement due to a first level TLB miss]
  tma_stlb_miss
       [Counts the number of cycles that the oldest load of the load buffer is
        stalled at retirement due to a second level TLB miss requiring a page
        walk]
  tma_store_fwd_blk
       [This metric roughly estimates fraction of cycles when the memory
        subsystem had loads blocked since they could not forward data from
        earlier (in program order) overlapping stores]
  tma_store_latency
       [This metric estimates fraction of cycles the CPU spent handling L1D
        store misses]
  tma_streaming_stores
       [This metric estimates how often CPU was stalled due to Streaming store
        memory accesses; Streaming store optimize out a read request required
        by RFO stores]
  tma_unknown_branches
       [This metric represents fraction of cycles the CPU was stalled due to
        new branch address clears]
  tma_x87_use
       [This metric serves as an approximation of legacy x87 usage]

TopdownL5: [Metrics for top-down breakdown at level 5]
  tma_alu_op_utilization
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution ports for ALU operations]
  tma_avx_assists
       [This metric estimates fraction of slots the CPU retired uops as a
        result of handing SSE to AVX* or AVX* to SSE transition Assists]
  tma_fp_assists
       [This metric roughly estimates fraction of slots the CPU retired uops
        as a result of handing Floating Point (FP) Assists]
  tma_fp_vector_128b
       [This metric approximates arithmetic FP vector uops fraction the CPU
        has retired for 128-bit wide vectors]
  tma_fp_vector_256b
       [This metric approximates arithmetic FP vector uops fraction the CPU
        has retired for 256-bit wide vectors]
  tma_load_op_utilization
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution port for Load operations]
  tma_load_stlb_hit
       [This metric roughly estimates the fraction of cycles where the (first
        level) DTLB was missed by load accesses, that later on hit in
        second-level TLB (STLB)]
  tma_load_stlb_miss
       [This metric estimates the fraction of cycles where the Second-level
        TLB (STLB) was missed by load accesses, performing a hardware page
        walk]
  tma_mixing_vectors
       [The Mixing_Vectors metric gives the percentage of injected blend uops
        out of all uops issued]
  tma_page_faults
       [This metric roughly estimates fraction of slots the CPU retired uops
        as a result of handing Page Faults]
  tma_serializing_operation
       [This metric represents fraction of cycles the CPU issue-pipeline was
        stalled due to serializing operations]
  tma_store_op_utilization
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution port for Store operations]
  tma_store_stlb_hit
       [This metric roughly estimates the fraction of cycles where the TLB was
        missed by store accesses, hitting in the second-level TLB (STLB)]
  tma_store_stlb_miss
       [This metric estimates the fraction of cycles where the STLB was missed
        by store accesses, performing a hardware page walk]

TopdownL6: [Metrics for top-down breakdown at level 6]
  tma_memory_fence
       [This metric represents fraction of cycles the CPU was stalled due to
        LFENCE Instructions]
  tma_port_0
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution port 0 ([SNB+] ALU; [HSW+] ALU and 2nd branch)]
  tma_port_1
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution port 1 (ALU)]
  tma_port_6
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution port 6 ([HSW+]Primary Branch and simple ALU)]
  tma_slow_pause
       [This metric represents fraction of cycles the CPU was stalled due to
        PAUSE Instructions]

smi:
  smi_cycles
       [Percentage of cycles spent in System Management Interrupts]
  smi_num
       [Number of SMI interrupts]

tma_L1_group: [Metrics for top-down breakdown at level 1]
  tma_backend_bound
       [This category represents fraction of slots where no uops are being
        delivered due to a lack of required resources for accepting new uops
        in the Backend]
  tma_backend_bound_aux
       [Counts the total number of issue slots that were not consumed by the
        backend due to backend stalls]
  tma_bad_speculation
       [This category represents fraction of slots wasted due to incorrect
        speculations]
  tma_frontend_bound
       [This category represents fraction of slots where the processor's
        Frontend undersupplies its Backend]
  tma_info_core_coreipc
       [Instructions Per Cycle across hyper-threads (per physical core)]
  tma_info_inst_mix_instructions
       [Total number of retired Instructions]
  tma_info_thread_slots
       [Total issue-pipeline slots (per-Physical Core till ICL; per-Logical
        Processor ICL onward)]
  tma_info_thread_slots_utilization
       [Fraction of Physical Core issue-slots utilized by this Logical
        Processor]
  tma_retiring
       [This category represents fraction of slots utilized by useful work
        i.e. issued uops that eventually get retired]

tma_L2_group: [Metrics for top-down breakdown at level 2]
  tma_base
       [Counts the number of uops that are not from the microsequencer]
  tma_branch_mispredicts
       [This metric represents fraction of slots the CPU has wasted due to
        Branch Misprediction]
  tma_core_bound
       [This metric represents fraction of slots where Core non-memory issues
        were of a bottleneck]
  tma_fetch_bandwidth
       [This metric represents fraction of slots the CPU was stalled due to
        Frontend bandwidth issues]
  tma_fetch_latency
       [This metric represents fraction of slots the CPU was stalled due to
        Frontend latency issues]
  tma_heavy_operations
       [This metric represents fraction of slots where the CPU was retiring
        heavy-weight operations -- instructions that require two or more uops
        or micro-coded sequences]
  tma_light_operations
       [This metric represents fraction of slots where the CPU was retiring
        light-weight operations -- instructions that require no more than one
        uop (micro-operation)]
  tma_machine_clears
       [This metric represents fraction of slots the CPU has wasted due to
        Machine Clears]
  tma_memory_bound
       [This metric represents fraction of slots the Memory subsystem within
        the Backend was a bottleneck]
  tma_ms_uops
       [Counts the number of uops that are from the complex flows issued by
        the micro-sequencer (MS)]
  tma_resource_bound
       [Counts the total number of issue slots that were not consumed by the
        backend due to backend stalls]

tma_L3_group: [Metrics for top-down breakdown at level 3]
  tma_alloc_restriction
       [Counts the number of issue slots that were not consumed by the backend
        due to certain allocation restrictions]
  tma_branch_detect
       [Counts the number of issue slots that were not delivered by the
        frontend due to BACLEARS, which occurs when the Branch Target Buffer
        (BTB) prediction or lack thereof, was corrected by a later branch
        predictor in the frontend]
  tma_branch_resteer
       [Counts the number of issue slots that were not delivered by the
        frontend due to BTCLEARS, which occurs when the Branch Target Buffer
        (BTB) predicts a taken branch]
  tma_branch_resteers
       [This metric represents fraction of cycles the CPU was stalled due to
        Branch Resteers]
  tma_cisc
       [Counts the number of issue slots that were not delivered by the
        frontend due to the microcode sequencer (MS)]
  tma_decode
       [Counts the number of issue slots that were not delivered by the
        frontend due to decode stalls]
  tma_divider
       [This metric represents fraction of cycles where the Divider unit was
        active]
  tma_dram_bound
       [This metric estimates how often the CPU was stalled on accesses to
        external memory (DRAM) by loads]
  tma_dsb
       [This metric represents Core fraction of cycles in which CPU was likely
        limited due to DSB (decoded uop cache) fetch pipeline]
  tma_dsb_switches
       [This metric represents fraction of cycles the CPU was stalled due to
        switches from DSB to MITE pipelines]
  tma_fast_nuke
       [Counts the number of issue slots that were not consumed by the backend
        due to a machine clear classified as a fast nuke due to memory
        ordering, memory disambiguation and memory renaming]
  tma_few_uops_instructions
       [This metric represents fraction of slots where the CPU was retiring
        instructions that that are decoder into two or up to ([SNB+] four;
        [ADL+] five) uops]
  tma_fp_arith
       [This metric represents overall arithmetic floating-point (FP)
        operations fraction the CPU has executed (retired)]
  tma_fpdiv_uops
       [Counts the number of floating point divide operations per uop]
  tma_fused_instructions
       [This metric represents fraction of slots where the CPU was retiring
        fused instructions -- where one uop can represent multiple contiguous
        instructions]
  tma_icache_misses
       [This metric represents fraction of cycles the CPU was stalled due to
        instruction cache misses]
  tma_int_operations
       [This metric represents overall Integer (Int) select operations
        fraction the CPU has executed (retired)]
  tma_itlb_misses
       [This metric represents fraction of cycles the CPU was stalled due to
        Instruction TLB (ITLB) misses]
  tma_l1_bound
       [This metric estimates how often the CPU was stalled without loads
        missing the L1 data cache]
  tma_l2_bound
       [This metric estimates how often the CPU was stalled due to L2 cache
        accesses by loads]
  tma_l3_bound
       [This metric estimates how often the CPU was stalled due to loads
        accesses to L3 cache or contended with a sibling Core]
  tma_lcp
       [This metric represents fraction of cycles CPU was stalled due to
        Length Changing Prefixes (LCPs)]
  tma_lsd
       [This metric represents Core fraction of cycles in which CPU was likely
        limited due to LSD (Loop Stream Detector) unit]
  tma_mem_scheduler
       [Counts the number of issue slots that were not consumed by the backend
        due to memory reservation stalls in which a scheduler is not able to
        accept uops]
  tma_memory_operations
       [This metric represents fraction of slots where the CPU was retiring
        memory operations -- uops for memory load or store accesses]
  tma_microcode_sequencer
       [This metric represents fraction of slots the CPU was retiring uops
        fetched by the Microcode Sequencer (MS) unit]
  tma_mite
       [This metric represents Core fraction of cycles in which CPU was likely
        limited due to the MITE pipeline (the legacy decode pipeline)]
  tma_ms_switches
       [This metric estimates the fraction of cycles when the CPU was stalled
        due to switches of uop delivery to the Microcode Sequencer (MS)]
  tma_non_fused_branches
       [This metric represents fraction of slots where the CPU was retiring
        branch instructions that were not fused]
  tma_non_mem_scheduler
       [Counts the number of issue slots that were not consumed by the backend
        due to IEC or FPC RAT stalls, which can be due to FIQ or IEC
        reservation stalls in which the integer, floating point or SIMD
        scheduler is not able to accept uops]
  tma_nop_instructions
       [This metric represents fraction of slots where the CPU was retiring
        NOP (no op) instructions]
  tma_nuke
       [Counts the number of issue slots that were not consumed by the backend
        due to a machine clear (slow nuke)]
  tma_other_fb
       [Counts the number of issue slots that were not delivered by the
        frontend due to other common frontend stalls not categorized]
  tma_other_light_ops
       [This metric represents the remaining light uops fraction the CPU has
        executed - remaining means not covered by other sibling nodes]
  tma_other_load_store
       [Counts the number of cycles the core is stalled due to a demand load
        miss which hits in the L2, LLC, DRAM or MMIO (Non-DRAM) but could not
        be correctly attributed or cycles in which the load miss is waiting on
        a request buffer]
  tma_other_ret
       [Counts the number of uops retired excluding ms and fp div uops]
  tma_ports_utilization
       [This metric estimates fraction of cycles the CPU performance was
        potentially limited due to Core computation issues (non
        divider-related)]
  tma_predecode
       [Counts the number of issue slots that were not delivered by the
        frontend due to wrong predecodes]
  tma_register
       [Counts the number of issue slots that were not consumed by the backend
        due to the physical register file unable to accept an entry (marble
        stalls)]
  tma_reorder_buffer
       [Counts the number of issue slots that were not consumed by the backend
        due to the reorder buffer being full (ROB stalls)]
  tma_serialization
       [Counts the number of issue slots that were not consumed by the backend
        due to scoreboards from the instruction queue (IQ), jump execution
        unit (JEU), or microcode sequencer (MS)]
  tma_store_bound
       [This metric estimates how often CPU was stalled due to RFO store
        memory accesses; RFO store issue a read-for-ownership request before
        the write]

tma_L4_group: [Metrics for top-down breakdown at level 4]
  tma_assists
       [This metric estimates fraction of slots the CPU retired uops delivered
        by the Microcode_Sequencer as a result of Assists]
  tma_cisc
       [This metric estimates fraction of cycles the CPU retired uops
        originated from CISC (complex instruction set computer) instruction]
  tma_clears_resteers
       [This metric represents fraction of cycles the CPU was stalled due to
        Branch Resteers as a result of Machine Clears]
  tma_contested_accesses
       [This metric estimates fraction of cycles while the memory subsystem
        was handling synchronizations due to contested accesses]
  tma_data_sharing
       [This metric estimates fraction of cycles while the memory subsystem
        was handling synchronizations due to data-sharing accesses]
  tma_decoder0_alone
       [This metric represents fraction of cycles where decoder-0 was the only
        active decoder]
  tma_disambiguation
       [Counts the number of machine clears relative to the number of nuke
        slots due to memory disambiguation]
  tma_dtlb_load
       [This metric roughly estimates the fraction of cycles where the Data
        TLB (DTLB) was missed by load accesses]
  tma_dtlb_store
       [This metric roughly estimates the fraction of cycles spent handling
        first-level data TLB store misses]
  tma_false_sharing
       [This metric roughly estimates how often CPU was handling
        synchronizations due to False Sharing]
  tma_fb_full
       [This metric does a *rough estimation* of how often L1D Fill Buffer
        unavailability limited additional L1D miss memory access requests to
        proceed]
  tma_fp_assist
       [Counts the number of machine clears relative to the number of nuke
        slots due to FP assists]
  tma_fp_scalar
       [This metric approximates arithmetic floating-point (FP) scalar uops
        fraction the CPU has retired]
  tma_fp_vector
       [This metric approximates arithmetic floating-point (FP) vector uops
        fraction the CPU has retired aggregated across all vector widths]
  tma_int_vector_128b
       [This metric represents 128-bit vector Integer ADD/SUB/SAD or VNNI
        (Vector Neural Network Instructions) uops fraction the CPU has retired]
  tma_int_vector_256b
       [This metric represents 256-bit vector Integer ADD/SUB/SAD or VNNI
        (Vector Neural Network Instructions) uops fraction the CPU has retired]
  tma_l3_hit_latency
       [This metric represents fraction of cycles with demand load accesses
        that hit the L3 cache under unloaded scenarios (possibly L3 latency
        limited)]
  tma_ld_buffer
       [Counts the number of cycles, relative to the number of mem_scheduler
        slots, in which uops are blocked due to load buffer full]
  tma_lock_latency
       [This metric represents fraction of cycles the CPU spent handling cache
        misses due to lock operations]
  tma_mem_bandwidth
       [This metric estimates fraction of cycles where the core's performance
        was likely hurt due to approaching bandwidth limits of external memory
        (DRAM)]
  tma_mem_latency
       [This metric estimates fraction of cycles where the performance was
        likely hurt due to latency from external memory (DRAM)]
  tma_memory_ordering
       [Counts the number of machine clears relative to the number of nuke
        slots due to memory ordering]
  tma_mispredicts_resteers
       [This metric represents fraction of cycles the CPU was stalled due to
        Branch Resteers as a result of Branch Misprediction at execution stage]
  tma_other_l1
       [Counts the number of cycles that the oldest load of the load buffer is
        stalled at retirement due to a number of other load blocks]
  tma_page_fault
       [Counts the number of machine clears relative to the number of nuke
        slots due to page faults]
  tma_ports_utilized_0
       [This metric represents fraction of cycles CPU executed no uops on any
        execution port (Logical Processor cycles since ICL, Physical Core
        cycles otherwise)]
  tma_ports_utilized_1
       [This metric represents fraction of cycles where the CPU executed total
        of 1 uop per cycle on all execution ports (Logical Processor cycles
        since ICL, Physical Core cycles otherwise)]
  tma_ports_utilized_2
       [This metric represents fraction of cycles CPU executed total of 2 uops
        per cycle on all execution ports (Logical Processor cycles since ICL,
        Physical Core cycles otherwise)]
  tma_ports_utilized_3m
       [This metric represents fraction of cycles CPU executed total of 3 or
        more uops per cycle on all execution ports (Logical Processor cycles
        since ICL, Physical Core cycles otherwise)]
  tma_rsv
       [Counts the number of cycles, relative to the number of mem_scheduler
        slots, in which uops are blocked due to RSV full relative]
  tma_shuffles
       [This metric represents Shuffle (cross "vector lane" data transfers)
        uops fraction the CPU has retired]
  tma_smc
       [Counts the number of machine clears relative to the number of nuke
        slots due to SMC]
  tma_split_loads
       [This metric estimates fraction of cycles handling memory load split
        accesses - load that cross 64-byte cache line boundary]
  tma_split_stores
       [This metric represents rate of split store accesses]
  tma_sq_full
       [This metric measures fraction of cycles where the Super Queue (SQ) was
        full taking into account all request-types and both hardware SMT
        threads (Logical Processors)]
  tma_st_buffer
       [Counts the number of cycles, relative to the number of mem_scheduler
        slots, in which uops are blocked due to store buffer full]
  tma_stlb_hit
       [Counts the number of cycles that the oldest load of the load buffer is
        stalled at retirement due to a first level TLB miss]
  tma_stlb_miss
       [Counts the number of cycles that the oldest load of the load buffer is
        stalled at retirement due to a second level TLB miss requiring a page
        walk]
  tma_store_fwd_blk
       [This metric roughly estimates fraction of cycles when the memory
        subsystem had loads blocked since they could not forward data from
        earlier (in program order) overlapping stores]
  tma_store_latency
       [This metric estimates fraction of cycles the CPU spent handling L1D
        store misses]
  tma_streaming_stores
       [This metric estimates how often CPU was stalled due to Streaming store
        memory accesses; Streaming store optimize out a read request required
        by RFO stores]
  tma_unknown_branches
       [This metric represents fraction of cycles the CPU was stalled due to
        new branch address clears]
  tma_x87_use
       [This metric serves as an approximation of legacy x87 usage]

tma_L5_group: [Metrics for top-down breakdown at level 5]
  tma_alu_op_utilization
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution ports for ALU operations]
  tma_avx_assists
       [This metric estimates fraction of slots the CPU retired uops as a
        result of handing SSE to AVX* or AVX* to SSE transition Assists]
  tma_fp_assists
       [This metric roughly estimates fraction of slots the CPU retired uops
        as a result of handing Floating Point (FP) Assists]
  tma_fp_vector_128b
       [This metric approximates arithmetic FP vector uops fraction the CPU
        has retired for 128-bit wide vectors]
  tma_fp_vector_256b
       [This metric approximates arithmetic FP vector uops fraction the CPU
        has retired for 256-bit wide vectors]
  tma_load_op_utilization
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution port for Load operations]
  tma_load_stlb_hit
       [This metric roughly estimates the fraction of cycles where the (first
        level) DTLB was missed by load accesses, that later on hit in
        second-level TLB (STLB)]
  tma_load_stlb_miss
       [This metric estimates the fraction of cycles where the Second-level
        TLB (STLB) was missed by load accesses, performing a hardware page
        walk]
  tma_mixing_vectors
       [The Mixing_Vectors metric gives the percentage of injected blend uops
        out of all uops issued]
  tma_page_faults
       [This metric roughly estimates fraction of slots the CPU retired uops
        as a result of handing Page Faults]
  tma_serializing_operation
       [This metric represents fraction of cycles the CPU issue-pipeline was
        stalled due to serializing operations]
  tma_store_op_utilization
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution port for Store operations]
  tma_store_stlb_hit
       [This metric roughly estimates the fraction of cycles where the TLB was
        missed by store accesses, hitting in the second-level TLB (STLB)]
  tma_store_stlb_miss
       [This metric estimates the fraction of cycles where the STLB was missed
        by store accesses, performing a hardware page walk]

tma_L6_group: [Metrics for top-down breakdown at level 6]
  tma_memory_fence
       [This metric represents fraction of cycles the CPU was stalled due to
        LFENCE Instructions]
  tma_port_0
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution port 0 ([SNB+] ALU; [HSW+] ALU and 2nd branch)]
  tma_port_1
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution port 1 (ALU)]
  tma_port_6
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution port 6 ([HSW+]Primary Branch and simple ALU)]
  tma_slow_pause
       [This metric represents fraction of cycles the CPU was stalled due to
        PAUSE Instructions]

tma_alu_op_utilization_group: [Metrics contributing to tma_alu_op_utilization category]
  tma_port_0
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution port 0 ([SNB+] ALU; [HSW+] ALU and 2nd branch)]
  tma_port_1
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution port 1 (ALU)]
  tma_port_6
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution port 6 ([HSW+]Primary Branch and simple ALU)]

tma_assists_group: [Metrics contributing to tma_assists category]
  tma_avx_assists
       [This metric estimates fraction of slots the CPU retired uops as a
        result of handing SSE to AVX* or AVX* to SSE transition Assists]
  tma_fp_assists
       [This metric roughly estimates fraction of slots the CPU retired uops
        as a result of handing Floating Point (FP) Assists]
  tma_page_faults
       [This metric roughly estimates fraction of slots the CPU retired uops
        as a result of handing Page Faults]

tma_backend_bound_aux_group: [Metrics contributing to tma_backend_bound_aux category]
  tma_resource_bound
       [Counts the total number of issue slots that were not consumed by the
        backend due to backend stalls]

tma_backend_bound_group: [Metrics contributing to tma_backend_bound category]
  tma_core_bound
       [This metric represents fraction of slots where Core non-memory issues
        were of a bottleneck]
  tma_memory_bound
       [This metric represents fraction of slots the Memory subsystem within
        the Backend was a bottleneck]

tma_bad_speculation_group: [Metrics contributing to tma_bad_speculation category]
  tma_branch_mispredicts
       [This metric represents fraction of slots the CPU has wasted due to
        Branch Misprediction]
  tma_machine_clears
       [This metric represents fraction of slots the CPU has wasted due to
        Machine Clears]

tma_base_group: [Metrics contributing to tma_base category]
  tma_fpdiv_uops
       [Counts the number of floating point divide operations per uop]
  tma_other_ret
       [Counts the number of uops retired excluding ms and fp div uops]

tma_branch_resteers_group: [Metrics contributing to tma_branch_resteers category]
  tma_clears_resteers
       [This metric represents fraction of cycles the CPU was stalled due to
        Branch Resteers as a result of Machine Clears]
  tma_mispredicts_resteers
       [This metric represents fraction of cycles the CPU was stalled due to
        Branch Resteers as a result of Branch Misprediction at execution stage]
  tma_unknown_branches
       [This metric represents fraction of cycles the CPU was stalled due to
        new branch address clears]

tma_core_bound_group: [Metrics contributing to tma_core_bound category]
  tma_divider
       [This metric represents fraction of cycles where the Divider unit was
        active]
  tma_ports_utilization
       [This metric estimates fraction of cycles the CPU performance was
        potentially limited due to Core computation issues (non
        divider-related)]

tma_dram_bound_group: [Metrics contributing to tma_dram_bound category]
  tma_mem_bandwidth
       [This metric estimates fraction of cycles where the core's performance
        was likely hurt due to approaching bandwidth limits of external memory
        (DRAM)]
  tma_mem_latency
       [This metric estimates fraction of cycles where the performance was
        likely hurt due to latency from external memory (DRAM)]

tma_dtlb_load_group: [Metrics contributing to tma_dtlb_load category]
  tma_load_stlb_hit
       [This metric roughly estimates the fraction of cycles where the (first
        level) DTLB was missed by load accesses, that later on hit in
        second-level TLB (STLB)]
  tma_load_stlb_miss
       [This metric estimates the fraction of cycles where the Second-level
        TLB (STLB) was missed by load accesses, performing a hardware page
        walk]

tma_dtlb_store_group: [Metrics contributing to tma_dtlb_store category]
  tma_store_stlb_hit
       [This metric roughly estimates the fraction of cycles where the TLB was
        missed by store accesses, hitting in the second-level TLB (STLB)]
  tma_store_stlb_miss
       [This metric estimates the fraction of cycles where the STLB was missed
        by store accesses, performing a hardware page walk]

tma_fetch_bandwidth_group: [Metrics contributing to tma_fetch_bandwidth category]
  tma_cisc
       [Counts the number of issue slots that were not delivered by the
        frontend due to the microcode sequencer (MS)]
  tma_decode
       [Counts the number of issue slots that were not delivered by the
        frontend due to decode stalls]
  tma_dsb
       [This metric represents Core fraction of cycles in which CPU was likely
        limited due to DSB (decoded uop cache) fetch pipeline]
  tma_lsd
       [This metric represents Core fraction of cycles in which CPU was likely
        limited due to LSD (Loop Stream Detector) unit]
  tma_mite
       [This metric represents Core fraction of cycles in which CPU was likely
        limited due to the MITE pipeline (the legacy decode pipeline)]
  tma_other_fb
       [Counts the number of issue slots that were not delivered by the
        frontend due to other common frontend stalls not categorized]
  tma_predecode
       [Counts the number of issue slots that were not delivered by the
        frontend due to wrong predecodes]

tma_fetch_latency_group: [Metrics contributing to tma_fetch_latency category]
  tma_branch_detect
       [Counts the number of issue slots that were not delivered by the
        frontend due to BACLEARS, which occurs when the Branch Target Buffer
        (BTB) prediction or lack thereof, was corrected by a later branch
        predictor in the frontend]
  tma_branch_resteer
       [Counts the number of issue slots that were not delivered by the
        frontend due to BTCLEARS, which occurs when the Branch Target Buffer
        (BTB) predicts a taken branch]
  tma_branch_resteers
       [This metric represents fraction of cycles the CPU was stalled due to
        Branch Resteers]
  tma_dsb_switches
       [This metric represents fraction of cycles the CPU was stalled due to
        switches from DSB to MITE pipelines]
  tma_icache_misses
       [This metric represents fraction of cycles the CPU was stalled due to
        instruction cache misses]
  tma_itlb_misses
       [This metric represents fraction of cycles the CPU was stalled due to
        Instruction TLB (ITLB) misses]
  tma_lcp
       [This metric represents fraction of cycles CPU was stalled due to
        Length Changing Prefixes (LCPs)]
  tma_ms_switches
       [This metric estimates the fraction of cycles when the CPU was stalled
        due to switches of uop delivery to the Microcode Sequencer (MS)]

tma_fp_arith_group: [Metrics contributing to tma_fp_arith category]
  tma_fp_scalar
       [This metric approximates arithmetic floating-point (FP) scalar uops
        fraction the CPU has retired]
  tma_fp_vector
       [This metric approximates arithmetic floating-point (FP) vector uops
        fraction the CPU has retired aggregated across all vector widths]
  tma_x87_use
       [This metric serves as an approximation of legacy x87 usage]

tma_fp_vector_group: [Metrics contributing to tma_fp_vector category]
  tma_fp_vector_128b
       [This metric approximates arithmetic FP vector uops fraction the CPU
        has retired for 128-bit wide vectors]
  tma_fp_vector_256b
       [This metric approximates arithmetic FP vector uops fraction the CPU
        has retired for 256-bit wide vectors]

tma_frontend_bound_group: [Metrics contributing to tma_frontend_bound category]
  tma_fetch_bandwidth
       [This metric represents fraction of slots the CPU was stalled due to
        Frontend bandwidth issues]
  tma_fetch_latency
       [This metric represents fraction of slots the CPU was stalled due to
        Frontend latency issues]

tma_heavy_operations_group: [Metrics contributing to tma_heavy_operations category]
  tma_few_uops_instructions
       [This metric represents fraction of slots where the CPU was retiring
        instructions that that are decoder into two or up to ([SNB+] four;
        [ADL+] five) uops]
  tma_microcode_sequencer
       [This metric represents fraction of slots the CPU was retiring uops
        fetched by the Microcode Sequencer (MS) unit]

tma_int_operations_group: [Metrics contributing to tma_int_operations category]
  tma_int_vector_128b
       [This metric represents 128-bit vector Integer ADD/SUB/SAD or VNNI
        (Vector Neural Network Instructions) uops fraction the CPU has retired]
  tma_int_vector_256b
       [This metric represents 256-bit vector Integer ADD/SUB/SAD or VNNI
        (Vector Neural Network Instructions) uops fraction the CPU has retired]
  tma_shuffles
       [This metric represents Shuffle (cross "vector lane" data transfers)
        uops fraction the CPU has retired]

tma_issue2P: [Metrics related by the issue $issue2P]
  tma_fp_scalar
       [This metric approximates arithmetic floating-point (FP) scalar uops
        fraction the CPU has retired]
  tma_fp_vector
       [This metric approximates arithmetic floating-point (FP) vector uops
        fraction the CPU has retired aggregated across all vector widths]
  tma_fp_vector_128b
       [This metric approximates arithmetic FP vector uops fraction the CPU
        has retired for 128-bit wide vectors]
  tma_fp_vector_256b
       [This metric approximates arithmetic FP vector uops fraction the CPU
        has retired for 256-bit wide vectors]
  tma_int_vector_128b
       [This metric represents 128-bit vector Integer ADD/SUB/SAD or VNNI
        (Vector Neural Network Instructions) uops fraction the CPU has retired]
  tma_int_vector_256b
       [This metric represents 256-bit vector Integer ADD/SUB/SAD or VNNI
        (Vector Neural Network Instructions) uops fraction the CPU has retired]
  tma_port_0
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution port 0 ([SNB+] ALU; [HSW+] ALU and 2nd branch)]
  tma_port_1
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution port 1 (ALU)]
  tma_port_6
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution port 6 ([HSW+]Primary Branch and simple ALU)]
  tma_ports_utilized_2
       [This metric represents fraction of cycles CPU executed total of 2 uops
        per cycle on all execution ports (Logical Processor cycles since ICL,
        Physical Core cycles otherwise)]

tma_issueBC: [Metrics related by the issue $issueBC]
  tma_info_bottleneck_big_code
       [Total pipeline cost of instruction fetch related bottlenecks by large
        code footprint programs (i-side cache; TLB and BTB misses)]
  tma_info_bottleneck_branching_overhead
       [Total pipeline cost of branch related instructions (used for program
        control-flow including function calls)]

tma_issueBM: [Metrics related by the issue $issueBM]
  tma_branch_mispredicts
       [This metric represents fraction of slots the CPU has wasted due to
        Branch Misprediction]
  tma_info_bad_spec_branch_misprediction_cost
       [Branch Misprediction Cost: Fraction of TMA slots wasted per
        non-speculative branch misprediction (retired JEClear)]
  tma_info_bottleneck_mispredictions
       [Total pipeline cost of Branch Misprediction related bottlenecks]
  tma_mispredicts_resteers
       [This metric represents fraction of cycles the CPU was stalled due to
        Branch Resteers as a result of Branch Misprediction at execution stage]

tma_issueBW: [Metrics related by the issue $issueBW]
  tma_fb_full
       [This metric does a *rough estimation* of how often L1D Fill Buffer
        unavailability limited additional L1D miss memory access requests to
        proceed]
  tma_info_bottleneck_memory_bandwidth
       [Total pipeline cost of (external) Memory Bandwidth related bottlenecks]
  tma_info_system_dram_bw_use
       [Average external Memory Bandwidth Use for reads and writes [GB / sec]]
  tma_mem_bandwidth
       [This metric estimates fraction of cycles where the core's performance
        was likely hurt due to approaching bandwidth limits of external memory
        (DRAM)]
  tma_sq_full
       [This metric measures fraction of cycles where the Super Queue (SQ) was
        full taking into account all request-types and both hardware SMT
        threads (Logical Processors)]

tma_issueD0: [Metrics related by the issue $issueD0]
  tma_decoder0_alone
       [This metric represents fraction of cycles where decoder-0 was the only
        active decoder]
  tma_few_uops_instructions
       [This metric represents fraction of slots where the CPU was retiring
        instructions that that are decoder into two or up to ([SNB+] four;
        [ADL+] five) uops]

tma_issueFB: [Metrics related by the issue $issueFB]
  tma_dsb_switches
       [This metric represents fraction of cycles the CPU was stalled due to
        switches from DSB to MITE pipelines]
  tma_fetch_bandwidth
       [This metric represents fraction of slots the CPU was stalled due to
        Frontend bandwidth issues]
  tma_info_botlnk_l2_dsb_misses
       [Total pipeline cost of DSB (uop cache) misses - subset of the
        Instruction_Fetch_BW Bottleneck]
  tma_info_frontend_dsb_coverage
       [Fraction of Uops delivered by the DSB (aka Decoded ICache; or Uop
        Cache)]
  tma_info_inst_mix_iptb
       [Instruction per taken branch]
  tma_lcp
       [This metric represents fraction of cycles CPU was stalled due to
        Length Changing Prefixes (LCPs)]

tma_issueFL: [Metrics related by the issue $issueFL]
  tma_info_botlnk_l2_ic_misses
       [Total pipeline cost of Instruction Cache misses - subset of the
        Big_Code Bottleneck]

tma_issueL1: [Metrics related by the issue $issueL1]
  tma_l1_bound
       [This metric estimates how often the CPU was stalled without loads
        missing the L1 data cache]
  tma_ports_utilized_1
       [This metric represents fraction of cycles where the CPU executed total
        of 1 uop per cycle on all execution ports (Logical Processor cycles
        since ICL, Physical Core cycles otherwise)]

tma_issueLat: [Metrics related by the issue $issueLat]
  tma_info_bottleneck_memory_latency
       [Total pipeline cost of Memory Latency related bottlenecks (external
        memory and off-core caches)]
  tma_l3_hit_latency
       [This metric represents fraction of cycles with demand load accesses
        that hit the L3 cache under unloaded scenarios (possibly L3 latency
        limited)]
  tma_mem_latency
       [This metric estimates fraction of cycles where the performance was
        likely hurt due to latency from external memory (DRAM)]

tma_issueMC: [Metrics related by the issue $issueMC]
  tma_clears_resteers
       [This metric represents fraction of cycles the CPU was stalled due to
        Branch Resteers as a result of Machine Clears]
  tma_l1_bound
       [This metric estimates how often the CPU was stalled without loads
        missing the L1 data cache]
  tma_machine_clears
       [This metric represents fraction of slots the CPU has wasted due to
        Machine Clears]
  tma_microcode_sequencer
       [This metric represents fraction of slots the CPU was retiring uops
        fetched by the Microcode Sequencer (MS) unit]
  tma_ms_switches
       [This metric estimates the fraction of cycles when the CPU was stalled
        due to switches of uop delivery to the Microcode Sequencer (MS)]

tma_issueMS: [Metrics related by the issue $issueMS]
  tma_microcode_sequencer
       [This metric represents fraction of slots the CPU was retiring uops
        fetched by the Microcode Sequencer (MS) unit]
  tma_ms_switches
       [This metric estimates the fraction of cycles when the CPU was stalled
        due to switches of uop delivery to the Microcode Sequencer (MS)]

tma_issueMV: [Metrics related by the issue $issueMV]
  tma_mixing_vectors
       [The Mixing_Vectors metric gives the percentage of injected blend uops
        out of all uops issued]
  tma_ms_switches
       [This metric estimates the fraction of cycles when the CPU was stalled
        due to switches of uop delivery to the Microcode Sequencer (MS)]

tma_issueRFO: [Metrics related by the issue $issueRFO]
  tma_lock_latency
       [This metric represents fraction of cycles the CPU spent handling cache
        misses due to lock operations]
  tma_store_latency
       [This metric estimates fraction of cycles the CPU spent handling L1D
        store misses]

tma_issueSL: [Metrics related by the issue $issueSL]
  tma_fb_full
       [This metric does a *rough estimation* of how often L1D Fill Buffer
        unavailability limited additional L1D miss memory access requests to
        proceed]
  tma_store_latency
       [This metric estimates fraction of cycles the CPU spent handling L1D
        store misses]

tma_issueSO: [Metrics related by the issue $issueSO]
  tma_ms_switches
       [This metric estimates the fraction of cycles when the CPU was stalled
        due to switches of uop delivery to the Microcode Sequencer (MS)]
  tma_serializing_operation
       [This metric represents fraction of cycles the CPU issue-pipeline was
        stalled due to serializing operations]

tma_issueSmSt: [Metrics related by the issue $issueSmSt]
  tma_fb_full
       [This metric does a *rough estimation* of how often L1D Fill Buffer
        unavailability limited additional L1D miss memory access requests to
        proceed]
  tma_streaming_stores
       [This metric estimates how often CPU was stalled due to Streaming store
        memory accesses; Streaming store optimize out a read request required
        by RFO stores]

tma_issueSpSt: [Metrics related by the issue $issueSpSt]
  tma_split_stores
       [This metric represents rate of split store accesses]

tma_issueSyncxn: [Metrics related by the issue $issueSyncxn]
  tma_contested_accesses
       [This metric estimates fraction of cycles while the memory subsystem
        was handling synchronizations due to contested accesses]
  tma_data_sharing
       [This metric estimates fraction of cycles while the memory subsystem
        was handling synchronizations due to data-sharing accesses]
  tma_false_sharing
       [This metric roughly estimates how often CPU was handling
        synchronizations due to False Sharing]
  tma_machine_clears
       [This metric represents fraction of slots the CPU has wasted due to
        Machine Clears]

tma_issueTLB: [Metrics related by the issue $issueTLB]
  tma_dtlb_load
       [This metric roughly estimates the fraction of cycles where the Data
        TLB (DTLB) was missed by load accesses]
  tma_dtlb_store
       [This metric roughly estimates the fraction of cycles spent handling
        first-level data TLB store misses]
  tma_info_bottleneck_memory_data_tlbs
       [Total pipeline cost of Memory Address Translation related bottlenecks
        (data-side TLBs)]

tma_l1_bound_group: [Metrics contributing to tma_l1_bound category]
  tma_dtlb_load
       [This metric roughly estimates the fraction of cycles where the Data
        TLB (DTLB) was missed by load accesses]
  tma_fb_full
       [This metric does a *rough estimation* of how often L1D Fill Buffer
        unavailability limited additional L1D miss memory access requests to
        proceed]
  tma_lock_latency
       [This metric represents fraction of cycles the CPU spent handling cache
        misses due to lock operations]
  tma_other_l1
       [Counts the number of cycles that the oldest load of the load buffer is
        stalled at retirement due to a number of other load blocks]
  tma_split_loads
       [This metric estimates fraction of cycles handling memory load split
        accesses - load that cross 64-byte cache line boundary]
  tma_stlb_hit
       [Counts the number of cycles that the oldest load of the load buffer is
        stalled at retirement due to a first level TLB miss]
  tma_stlb_miss
       [Counts the number of cycles that the oldest load of the load buffer is
        stalled at retirement due to a second level TLB miss requiring a page
        walk]
  tma_store_fwd_blk
       [This metric roughly estimates fraction of cycles when the memory
        subsystem had loads blocked since they could not forward data from
        earlier (in program order) overlapping stores]

tma_l3_bound_group: [Metrics contributing to tma_l3_bound category]
  tma_contested_accesses
       [This metric estimates fraction of cycles while the memory subsystem
        was handling synchronizations due to contested accesses]
  tma_data_sharing
       [This metric estimates fraction of cycles while the memory subsystem
        was handling synchronizations due to data-sharing accesses]
  tma_l3_hit_latency
       [This metric represents fraction of cycles with demand load accesses
        that hit the L3 cache under unloaded scenarios (possibly L3 latency
        limited)]
  tma_sq_full
       [This metric measures fraction of cycles where the Super Queue (SQ) was
        full taking into account all request-types and both hardware SMT
        threads (Logical Processors)]

tma_light_operations_group: [Metrics contributing to tma_light_operations category]
  tma_fp_arith
       [This metric represents overall arithmetic floating-point (FP)
        operations fraction the CPU has executed (retired)]
  tma_fused_instructions
       [This metric represents fraction of slots where the CPU was retiring
        fused instructions -- where one uop can represent multiple contiguous
        instructions]
  tma_int_operations
       [This metric represents overall Integer (Int) select operations
        fraction the CPU has executed (retired)]
  tma_memory_operations
       [This metric represents fraction of slots where the CPU was retiring
        memory operations -- uops for memory load or store accesses]
  tma_non_fused_branches
       [This metric represents fraction of slots where the CPU was retiring
        branch instructions that were not fused]
  tma_nop_instructions
       [This metric represents fraction of slots where the CPU was retiring
        NOP (no op) instructions]
  tma_other_light_ops
       [This metric represents the remaining light uops fraction the CPU has
        executed - remaining means not covered by other sibling nodes]

tma_machine_clears_group: [Metrics contributing to tma_machine_clears category]
  tma_fast_nuke
       [Counts the number of issue slots that were not consumed by the backend
        due to a machine clear classified as a fast nuke due to memory
        ordering, memory disambiguation and memory renaming]
  tma_nuke
       [Counts the number of issue slots that were not consumed by the backend
        due to a machine clear (slow nuke)]

tma_mem_scheduler_group: [Metrics contributing to tma_mem_scheduler category]
  tma_ld_buffer
       [Counts the number of cycles, relative to the number of mem_scheduler
        slots, in which uops are blocked due to load buffer full]
  tma_rsv
       [Counts the number of cycles, relative to the number of mem_scheduler
        slots, in which uops are blocked due to RSV full relative]
  tma_st_buffer
       [Counts the number of cycles, relative to the number of mem_scheduler
        slots, in which uops are blocked due to store buffer full]

tma_memory_bound_group: [Metrics contributing to tma_memory_bound category]
  tma_dram_bound
       [This metric estimates how often the CPU was stalled on accesses to
        external memory (DRAM) by loads]
  tma_l1_bound
       [This metric estimates how often the CPU was stalled without loads
        missing the L1 data cache]
  tma_l2_bound
       [This metric estimates how often the CPU was stalled due to L2 cache
        accesses by loads]
  tma_l3_bound
       [This metric estimates how often the CPU was stalled due to loads
        accesses to L3 cache or contended with a sibling Core]
  tma_other_load_store
       [Counts the number of cycles the core is stalled due to a demand load
        miss which hits in the L2, LLC, DRAM or MMIO (Non-DRAM) but could not
        be correctly attributed or cycles in which the load miss is waiting on
        a request buffer]
  tma_store_bound
       [This metric estimates how often CPU was stalled due to RFO store
        memory accesses; RFO store issue a read-for-ownership request before
        the write]

tma_microcode_sequencer_group: [Metrics contributing to tma_microcode_sequencer category]
  tma_assists
       [This metric estimates fraction of slots the CPU retired uops delivered
        by the Microcode_Sequencer as a result of Assists]
  tma_cisc
       [This metric estimates fraction of cycles the CPU retired uops
        originated from CISC (complex instruction set computer) instruction]

tma_mite_group: [Metrics contributing to tma_mite category]
  tma_decoder0_alone
       [This metric represents fraction of cycles where decoder-0 was the only
        active decoder]

tma_nuke_group: [Metrics contributing to tma_nuke category]
  tma_disambiguation
       [Counts the number of machine clears relative to the number of nuke
        slots due to memory disambiguation]
  tma_fp_assist
       [Counts the number of machine clears relative to the number of nuke
        slots due to FP assists]
  tma_memory_ordering
       [Counts the number of machine clears relative to the number of nuke
        slots due to memory ordering]
  tma_page_fault
       [Counts the number of machine clears relative to the number of nuke
        slots due to page faults]
  tma_smc
       [Counts the number of machine clears relative to the number of nuke
        slots due to SMC]

tma_ports_utilization_group: [Metrics contributing to tma_ports_utilization category]
  tma_ports_utilized_0
       [This metric represents fraction of cycles CPU executed no uops on any
        execution port (Logical Processor cycles since ICL, Physical Core
        cycles otherwise)]
  tma_ports_utilized_1
       [This metric represents fraction of cycles where the CPU executed total
        of 1 uop per cycle on all execution ports (Logical Processor cycles
        since ICL, Physical Core cycles otherwise)]
  tma_ports_utilized_2
       [This metric represents fraction of cycles CPU executed total of 2 uops
        per cycle on all execution ports (Logical Processor cycles since ICL,
        Physical Core cycles otherwise)]
  tma_ports_utilized_3m
       [This metric represents fraction of cycles CPU executed total of 3 or
        more uops per cycle on all execution ports (Logical Processor cycles
        since ICL, Physical Core cycles otherwise)]

tma_ports_utilized_0_group: [Metrics contributing to tma_ports_utilized_0 category]
  tma_mixing_vectors
       [The Mixing_Vectors metric gives the percentage of injected blend uops
        out of all uops issued]
  tma_serializing_operation
       [This metric represents fraction of cycles the CPU issue-pipeline was
        stalled due to serializing operations]

tma_ports_utilized_3m_group: [Metrics contributing to tma_ports_utilized_3m category]
  tma_alu_op_utilization
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution ports for ALU operations]
  tma_load_op_utilization
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution port for Load operations]
  tma_store_op_utilization
       [This metric represents Core fraction of cycles CPU dispatched uops on
        execution port for Store operations]

tma_resource_bound_group: [Metrics contributing to tma_resource_bound category]
  tma_alloc_restriction
       [Counts the number of issue slots that were not consumed by the backend
        due to certain allocation restrictions]
  tma_mem_scheduler
       [Counts the number of issue slots that were not consumed by the backend
        due to memory reservation stalls in which a scheduler is not able to
        accept uops]
  tma_non_mem_scheduler
       [Counts the number of issue slots that were not consumed by the backend
        due to IEC or FPC RAT stalls, which can be due to FIQ or IEC
        reservation stalls in which the integer, floating point or SIMD
        scheduler is not able to accept uops]
  tma_register
       [Counts the number of issue slots that were not consumed by the backend
        due to the physical register file unable to accept an entry (marble
        stalls)]
  tma_reorder_buffer
       [Counts the number of issue slots that were not consumed by the backend
        due to the reorder buffer being full (ROB stalls)]
  tma_serialization
       [Counts the number of issue slots that were not consumed by the backend
        due to scoreboards from the instruction queue (IQ), jump execution
        unit (JEU), or microcode sequencer (MS)]

tma_retiring_group: [Metrics contributing to tma_retiring category]
  tma_base
       [Counts the number of uops that are not from the microsequencer]
  tma_heavy_operations
       [This metric represents fraction of slots where the CPU was retiring
        heavy-weight operations -- instructions that require two or more uops
        or micro-coded sequences]
  tma_light_operations
       [This metric represents fraction of slots where the CPU was retiring
        light-weight operations -- instructions that require no more than one
        uop (micro-operation)]
  tma_ms_uops
       [Counts the number of uops that are from the complex flows issued by
        the micro-sequencer (MS)]

tma_serializing_operation_group: [Metrics contributing to tma_serializing_operation category]
  tma_memory_fence
       [This metric represents fraction of cycles the CPU was stalled due to
        LFENCE Instructions]
  tma_slow_pause
       [This metric represents fraction of cycles the CPU was stalled due to
        PAUSE Instructions]

tma_store_bound_group: [Metrics contributing to tma_store_bound category]
  tma_dtlb_store
       [This metric roughly estimates the fraction of cycles spent handling
        first-level data TLB store misses]
  tma_false_sharing
       [This metric roughly estimates how often CPU was handling
        synchronizations due to False Sharing]
  tma_split_stores
       [This metric represents rate of split store accesses]
  tma_store_latency
       [This metric estimates fraction of cycles the CPU spent handling L1D
        store misses]
  tma_streaming_stores
       [This metric estimates how often CPU was stalled due to Streaming store
        memory accesses; Streaming store optimize out a read request required
        by RFO stores]

transaction:
  tsx_aborted_cycles
       [Percentage of cycles in aborted transactions]
  tsx_cycles_per_elision
       [Number of cycles within a transaction divided by the number of
        elisions]
  tsx_cycles_per_transaction
       [Number of cycles within a transaction divided by the number of
        transactions]
  tsx_transactional_cycles
       [Percentage of cycles within a transaction region]
